{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b1c13c80",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction Problem Report\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f36ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d4b16",
   "metadata": {},
   "source": [
    "## 1) Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc06dc",
   "metadata": {},
   "source": [
    "The acceptance rate column had unnecessary characters so in my cleaning I removed those and converted to numeric values. Along with that, I transformed the date columns to numeric by calculated \"months since\" each respective date. True/False columns were converted to 1/0. There were many values for neighbourhood so I grouped any neighbourhood with less than 200 value counts into 'Other'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eaefd",
   "metadata": {},
   "source": [
    "## 2) Data Cleaning/Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4abb9",
   "metadata": {},
   "source": [
    "Mention the data cleaning/preparation steps you took to prepare your data. This may include imputing missing values, creating dummy variables, combining levels of categorical variable(s), discarding predictors that are not useful, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efccf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('train_classification.csv')\n",
    "raw_test = pd.read_csv('test_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b377802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and process the data\n",
    "train = raw_train.copy()\n",
    "\n",
    "# Process acceptance rates\n",
    "train['host_acceptance_rate'] = train['host_acceptance_rate'].str.replace('%', '').astype(float)\n",
    "train['host_response_rate'] = train['host_response_rate'].str.replace('%', '').astype(float)\n",
    "\n",
    "# Process bathroom column into numeric column\n",
    "train['bathrooms_num'] = train['bathrooms_text'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "# Convert date columns\n",
    "train['host_since_years'] = ((datetime.now() - pd.to_datetime(train['host_since'])).dt.days) / 365\n",
    "train['first_review_years'] = ((datetime.now() - pd.to_datetime(train['first_review'])).dt.days) / 365\n",
    "train['last_review_years'] = ((datetime.now() - pd.to_datetime(train['last_review'])).dt.days) / 365\n",
    "\n",
    "t_f_vars = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'instant_bookable']\n",
    "train[t_f_vars] = train[t_f_vars].replace({'f': 0, 't': 1})\n",
    "\n",
    "\n",
    "def is_shared(x):\n",
    "    if str(x) == 'nan':\n",
    "        return False\n",
    "    else:\n",
    "        if 'shared' in x:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "train['bathrooms_shared'] = train['bathrooms_text'].apply(is_shared).astype(int)\n",
    "\n",
    "train_clean = train.drop(columns=['host_since', 'first_review', 'last_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6087c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and process the data\n",
    "test = raw_test.copy()\n",
    "\n",
    "# Process acceptance rates\n",
    "test['host_acceptance_rate'] = test['host_acceptance_rate'].str.replace('%', '').astype(float)\n",
    "test['host_response_rate'] = test['host_response_rate'].str.replace('%', '').astype(float)\n",
    "\n",
    "# Process bathroom column into numeric column\n",
    "test['bathrooms_num'] = test['bathrooms_text'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "\n",
    "# Convert date columns\n",
    "test['host_since_years'] = ((datetime.now() - pd.to_datetime(test['host_since'])).dt.days) / 365\n",
    "# test['first_review_diff_days'] = (datetime.now() - pd.to_datetime(test['first_review'])).dt.days\n",
    "test['last_review_years'] = ((datetime.now() - pd.to_datetime(test['last_review'])).dt.days) / 365\n",
    "\n",
    "\n",
    "t_f_vars = ['host_has_profile_pic', 'host_identity_verified', 'has_availability', 'instant_bookable']\n",
    "test[t_f_vars] = test[t_f_vars].replace({'f': False, 't': True})\n",
    "\n",
    "\n",
    "test['bathrooms_shared'] = test['bathrooms_text'].apply(is_shared).astype(int)\n",
    "\n",
    "\n",
    "test_clean = test.drop(columns=['host_since', 'first_review', 'last_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1adf2c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire home/apt    3801\n",
      "Single room        1176\n",
      "Name: room_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Neighbourhoods with <400 observations are 'Other'\n",
    "\n",
    "location_counts = train_clean['host_location'].value_counts()\n",
    "\n",
    "test_only_hoods = [i for i in test_clean['host_location'].unique() \n",
    "                   if i not in location_counts \n",
    "                   and i != 'Other']\n",
    "\n",
    "other_hoods = []\n",
    "for i in location_counts.index:\n",
    "    if location_counts[i] < 350:\n",
    "        other_hoods.append(i)         \n",
    "    \n",
    "def clean_hoods(row):\n",
    "    if row.loc['host_location'] in other_hoods:\n",
    "        row['host_location'] = 'Other'\n",
    "    if row.loc['host_location'] in test_only_hoods:\n",
    "        row['host_location'] = 'Other'\n",
    "    return row\n",
    "       \n",
    "def clean_rooms(row):    \n",
    "    if row.loc['room_type'] == 'Hotel room' or row.loc['room_type'] == 'Private room' or row.loc['room_type'] == 'Shared room':\n",
    "        row['room_type'] = 'Single room'\n",
    "    return row\n",
    "    \n",
    "\n",
    "    \n",
    "train_clean = train_clean.apply(clean_rooms, axis=1)\n",
    "test_clean = test_clean.apply(clean_rooms, axis=1)\n",
    "print(train_clean['room_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38bbe404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train_clean.apply(clean_hoods, axis=1)  \n",
    "test_clean = test_clean.apply(clean_hoods, axis=1)  \n",
    "# train_clean['neighbourhood_cleansed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62562791",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d014e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_model = smf.ols(formula='host_acceptance_rate~C(instant_bookable)', data=train_clean).fit()\n",
    "acceptance_model.summary()\n",
    "\n",
    "train_clean['imputed_acceptance_rate'] = acceptance_model.predict(train_clean)\n",
    "train_clean['host_acceptance_rate'].fillna(train_clean['imputed_acceptance_rate'], inplace=True)\n",
    "train_clean.drop(columns=['imputed_acceptance_rate'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a03db",
   "metadata": {},
   "source": [
    "## 3) Developing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d864c3",
   "metadata": {},
   "source": [
    "Host_response_rate was included because it makes sense because a higher rate probably means a more attentive and better host. host_since_years was included because more experience would make a better host. host_total_listings_count\\*number_of_reviews_ltm should be evaluated together because the number of reviews will directly depend on how many listings a host has. review_scores_cleanliness is another variable that intuitively would connect to the quality of a host. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e104de7",
   "metadata": {},
   "source": [
    "## 4) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6462944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532047\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>host_is_superhost</td> <th>  No. Observations:  </th>   <td>  3660</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>       <th>  Df Residuals:      </th>   <td>  3647</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>        <th>  Df Model:          </th>   <td>    12</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 18 Feb 2024</td>  <th>  Pseudo R-squ.:     </th>   <td>0.2288</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:39:45</td>      <th>  Log-Likelihood:    </th>  <td> -1947.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>        <th>  LL-Null:           </th>  <td> -2525.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>6.247e-240</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                         <td></td>                            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                       <td>   -4.1606</td> <td>    2.011</td> <td>   -2.068</td> <td> 0.039</td> <td>   -8.103</td> <td>   -0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_total_listings_count</th>                       <td>   -0.0030</td> <td>    0.001</td> <td>   -3.184</td> <td> 0.001</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_reviews_ltm</th>                           <td>   -0.1015</td> <td>    0.057</td> <td>   -1.779</td> <td> 0.075</td> <td>   -0.213</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_total_listings_count:number_of_reviews_ltm</th> <td>   -0.0005</td> <td> 7.09e-05</td> <td>   -6.773</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_response_rate</th>                              <td>    0.0162</td> <td>    0.007</td> <td>    2.285</td> <td> 0.022</td> <td>    0.002</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_reviews_ltm:host_response_rate</th>        <td>    0.0023</td> <td>    0.000</td> <td>    5.873</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_acceptance_rate</th>                            <td>    0.0184</td> <td>    0.004</td> <td>    5.128</td> <td> 0.000</td> <td>    0.011</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_acceptance_rate:number_of_reviews_ltm</th>      <td>   -0.0009</td> <td>    0.000</td> <td>   -2.307</td> <td> 0.021</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>availability_90</th>                                 <td>   -0.0019</td> <td>    0.001</td> <td>   -1.736</td> <td> 0.083</td> <td>   -0.004</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_scores_cleanliness</th>                       <td>   -1.8528</td> <td>    0.639</td> <td>   -2.901</td> <td> 0.004</td> <td>   -3.105</td> <td>   -0.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(review_scores_cleanliness ** 3)</th>               <td>    0.0825</td> <td>    0.011</td> <td>    7.478</td> <td> 0.000</td> <td>    0.061</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_since_years</th>                                <td>    0.0658</td> <td>    0.012</td> <td>    5.408</td> <td> 0.000</td> <td>    0.042</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_since_years:host_total_listings_count</th>      <td>    0.0003</td> <td> 9.65e-05</td> <td>    3.072</td> <td> 0.002</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                        & host\\_is\\_superhost & \\textbf{  No. Observations:  } &     3660    \\\\\n",
       "\\textbf{Model:}                                                &        Logit        & \\textbf{  Df Residuals:      } &     3647    \\\\\n",
       "\\textbf{Method:}                                               &         MLE         & \\textbf{  Df Model:          } &       12    \\\\\n",
       "\\textbf{Date:}                                                 &   Sun, 18 Feb 2024  & \\textbf{  Pseudo R-squ.:     } &   0.2288    \\\\\n",
       "\\textbf{Time:}                                                 &       14:39:45      & \\textbf{  Log-Likelihood:    } &   -1947.3   \\\\\n",
       "\\textbf{converged:}                                            &         True        & \\textbf{  LL-Null:           } &   -2525.1   \\\\\n",
       "\\textbf{Covariance Type:}                                      &      nonrobust      & \\textbf{  LLR p-value:       } & 6.247e-240  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                             &      -4.1606  &        2.011     &    -2.068  &         0.039        &       -8.103    &       -0.218     \\\\\n",
       "\\textbf{host\\_total\\_listings\\_count}                          &      -0.0030  &        0.001     &    -3.184  &         0.001        &       -0.005    &       -0.001     \\\\\n",
       "\\textbf{number\\_of\\_reviews\\_ltm}                              &      -0.1015  &        0.057     &    -1.779  &         0.075        &       -0.213    &        0.010     \\\\\n",
       "\\textbf{host\\_total\\_listings\\_count:number\\_of\\_reviews\\_ltm} &      -0.0005  &     7.09e-05     &    -6.773  &         0.000        &       -0.001    &       -0.000     \\\\\n",
       "\\textbf{host\\_response\\_rate}                                  &       0.0162  &        0.007     &     2.285  &         0.022        &        0.002    &        0.030     \\\\\n",
       "\\textbf{number\\_of\\_reviews\\_ltm:host\\_response\\_rate}         &       0.0023  &        0.000     &     5.873  &         0.000        &        0.002    &        0.003     \\\\\n",
       "\\textbf{host\\_acceptance\\_rate}                                &       0.0184  &        0.004     &     5.128  &         0.000        &        0.011    &        0.025     \\\\\n",
       "\\textbf{host\\_acceptance\\_rate:number\\_of\\_reviews\\_ltm}       &      -0.0009  &        0.000     &    -2.307  &         0.021        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{availability\\_90}                                      &      -0.0019  &        0.001     &    -1.736  &         0.083        &       -0.004    &        0.000     \\\\\n",
       "\\textbf{review\\_scores\\_cleanliness}                           &      -1.8528  &        0.639     &    -2.901  &         0.004        &       -3.105    &       -0.601     \\\\\n",
       "\\textbf{I(review\\_scores\\_cleanliness ** 3)}                   &       0.0825  &        0.011     &     7.478  &         0.000        &        0.061    &        0.104     \\\\\n",
       "\\textbf{host\\_since\\_years}                                    &       0.0658  &        0.012     &     5.408  &         0.000        &        0.042    &        0.090     \\\\\n",
       "\\textbf{host\\_since\\_years:host\\_total\\_listings\\_count}       &       0.0003  &     9.65e-05     &     3.072  &         0.002        &        0.000    &        0.000     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:      host_is_superhost   No. Observations:                 3660\n",
       "Model:                          Logit   Df Residuals:                     3647\n",
       "Method:                           MLE   Df Model:                           12\n",
       "Date:                Sun, 18 Feb 2024   Pseudo R-squ.:                  0.2288\n",
       "Time:                        14:39:45   Log-Likelihood:                -1947.3\n",
       "converged:                       True   LL-Null:                       -2525.1\n",
       "Covariance Type:            nonrobust   LLR p-value:                6.247e-240\n",
       "===================================================================================================================\n",
       "                                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                          -4.1606      2.011     -2.068      0.039      -8.103      -0.218\n",
       "host_total_listings_count                          -0.0030      0.001     -3.184      0.001      -0.005      -0.001\n",
       "number_of_reviews_ltm                              -0.1015      0.057     -1.779      0.075      -0.213       0.010\n",
       "host_total_listings_count:number_of_reviews_ltm    -0.0005   7.09e-05     -6.773      0.000      -0.001      -0.000\n",
       "host_response_rate                                  0.0162      0.007      2.285      0.022       0.002       0.030\n",
       "number_of_reviews_ltm:host_response_rate            0.0023      0.000      5.873      0.000       0.002       0.003\n",
       "host_acceptance_rate                                0.0184      0.004      5.128      0.000       0.011       0.025\n",
       "host_acceptance_rate:number_of_reviews_ltm         -0.0009      0.000     -2.307      0.021      -0.002      -0.000\n",
       "availability_90                                    -0.0019      0.001     -1.736      0.083      -0.004       0.000\n",
       "review_scores_cleanliness                          -1.8528      0.639     -2.901      0.004      -3.105      -0.601\n",
       "I(review_scores_cleanliness ** 3)                   0.0825      0.011      7.478      0.000       0.061       0.104\n",
       "host_since_years                                    0.0658      0.012      5.408      0.000       0.042       0.090\n",
       "host_since_years:host_total_listings_count          0.0003   9.65e-05      3.072      0.002       0.000       0.000\n",
       "===================================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the code that develops the model using the data you processed in Question 2, \n",
    "# and then uses the developed model on test data for prediction.\n",
    "formula= '''host_is_superhost ~ host_total_listings_count*number_of_reviews_ltm + \n",
    "number_of_reviews_ltm*host_response_rate + host_acceptance_rate*number_of_reviews_ltm +\n",
    "availability_90 + \n",
    "review_scores_cleanliness + I(review_scores_cleanliness**3) + \n",
    "host_since_years*host_total_listings_count'''\n",
    "\n",
    "model = smf.logit(formula=formula, data=train_clean).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491e8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(thresh):\n",
    "    y_pred_temp = model.predict(train_clean) > thresh\n",
    "    acc_score = accuracy_score(train_clean.host_is_superhost, y_pred_temp)\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e9ba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 0.7578862768736186, 0.54)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds1 = np.linspace(0.4, 0.6, num=21)\n",
    "accuracies1 = []\n",
    "accuracies1 = pd.Series(thresholds1).apply(get_acc)\n",
    "\n",
    "idx1 = accuracies1.idxmax()\n",
    "idx1, accuracies1[idx1], thresholds1[idx1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f09c8a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 0.7584890496282901, 0.5316000000000001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds2 = np.linspace(thresholds1[idx1-1], thresholds1[idx1+1], num=101)\n",
    "    \n",
    "accuracies2 = []\n",
    "accuracies2 = pd.Series(thresholds2).apply(get_acc)\n",
    "\n",
    "idx2 = accuracies2.idxmax()\n",
    "idx2, accuracies2[idx2], thresholds2[idx2]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a474da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 0.7584890496282901, 0.5316000000000001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds3 = np.linspace(thresholds2[idx2-1], thresholds2[idx2+1], num=101)\n",
    "\n",
    "accuracies3 = []\n",
    "accuracies3 = pd.Series(thresholds3).apply(get_acc)\n",
    "\n",
    "idx3 = accuracies3.idxmax()\n",
    "idx3, accuracies3[idx3], thresholds3[idx3]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3e39311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2813\n",
       "True     2164\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = round(thresholds3[idx3], 6)\n",
    "\n",
    "y_pred = model.predict(train_clean) > threshold\n",
    "\n",
    "y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b9e41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR: 21.16\tFNR: 27.9762\n",
      "Accuracy: 75.8489\n",
      "Precision: 72.6895\n",
      "Recall: 72.0238\n",
      "\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0         2202          591\n",
      "Actual 1          611         1573\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_clean.host_is_superhost, y_pred).ravel()\n",
    "\n",
    "FPR = round(100*(fp / (fp + tn)), 4)\n",
    "FNR = round(100*(fn / (fn + tp)), 4)\n",
    "\n",
    "print(f\"FPR: {FPR}\\tFNR: {FNR}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(train_clean.host_is_superhost, y_pred)\n",
    "conf_df = pd.DataFrame(conf_matrix, columns=[\"Predicted 0\", \"Predicted 1\"], index=[\"Actual 0\", \"Actual 1\"])\n",
    "acc_score = round(accuracy_score(train_clean.host_is_superhost, y_pred) * 100, 4)\n",
    "precision = round(precision_score(train_clean.host_is_superhost, y_pred) * 100, 4)\n",
    "recall = round(recall_score(train_clean.host_is_superhost, y_pred)*100, 4)\n",
    "\n",
    "print(f\"Accuracy: {acc_score}\\nPrecision: {precision}\\nRecall: {recall}\")\n",
    "print(f\"\\n{conf_df}\")\n",
    "\n",
    "# tn, fp\n",
    "# fn, tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe29ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (model.predict(test_clean) > threshold).replace({False:0, True:1})\n",
    "\n",
    "predicted_values = pd.concat([test_clean['id'], test_pred], axis=1).set_index('id').rename(columns={0:'predicted'})\n",
    "\n",
    "predicted_values.to_csv('classification_model_results.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
