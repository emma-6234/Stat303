{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "f042038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, RidgeCV, LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import date, datetime\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "055d7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('datasets/train_regression.csv')\n",
    "raw_test = pd.read_csv('datasets/test_regression.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe14fa6",
   "metadata": {},
   "source": [
    "## Clean and Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6255b",
   "metadata": {},
   "source": [
    "### General Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a21065c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_train.copy()\n",
    "test = raw_test.copy()\n",
    "\n",
    "train['price'] = train['price'].str.replace(',', '').str.replace('$', '', regex=False).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c53ec301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['acceptance_rate'] = train['host_acceptance_rate'].str.replace('%', '').astype(float) / 100\n",
    "train['response_rate'] = train['host_response_rate'].str.replace('%', '').astype(float) / 100\n",
    "\n",
    "test['acceptance_rate'] = test['host_acceptance_rate'].str.replace('%', '').astype(float) / 100\n",
    "test['response_rate'] = test['host_response_rate'].str.replace('%', '').astype(float) / 100\n",
    "\n",
    "train.drop(columns=['host_acceptance_rate', 'host_response_rate'], inplace=True)\n",
    "test.drop(columns=['host_acceptance_rate', 'host_response_rate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b0fdd28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bathrooms_num'] = train['bathrooms_text'].str.extract('(\\d+)').astype(float)\n",
    "test['bathrooms_num'] = test['bathrooms_text'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "train.loc[train['bathrooms_text'].str.contains('Half-bath', case=False, na=False) & train['bathrooms_num'].isna(), 'bathrooms_num'] = 0.5\n",
    "test.loc[test['bathrooms_text'].str.contains('Half-bath', case=False, na=False) & test['bathrooms_num'].isna(), 'bathrooms_num'] = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "ace60bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns\n",
    "def strip_date(row):\n",
    "    if isinstance(row, str):\n",
    "        row = datetime.strptime(row, '%Y-%m-%d').date()\n",
    "    return row\n",
    "\n",
    "# Apply date conversion to train dataset\n",
    "train['host_since'] = train['host_since'].apply(strip_date)\n",
    "train['first_review'] = train['first_review'].apply(strip_date)\n",
    "train['last_review'] = train['last_review'].apply(strip_date)\n",
    "\n",
    "# Apply date conversion to test dataset\n",
    "test['host_since'] = test['host_since'].apply(strip_date)\n",
    "test['first_review'] = test['first_review'].apply(strip_date)\n",
    "test['last_review'] = test['last_review'].apply(strip_date)\n",
    "\n",
    "# ----- #\n",
    "\n",
    "# Calculate months since various dates for train dataset\n",
    "train['host_since_in_months'] = round(((datetime.now().date() - train['host_since']).dt.days) / 30, 2)\n",
    "train['first_review_in_months'] = round(((datetime.now().date() - train['first_review']).dt.days) / 30, 2)\n",
    "train['last_review_in_months'] = round(((datetime.now().date() - train['last_review']).dt.days) / 30, 2)\n",
    "\n",
    "# Calculate months since various dates for test dataset\n",
    "test['host_since_in_months'] = round(((datetime.now().date() - test['host_since']).dt.days) / 30,  2)\n",
    "test['first_review_in_months'] = round(((datetime.now().date() - test['first_review']).dt.days) / 30, 2)\n",
    "test['last_review_in_months'] = round(((datetime.now().date() - test['last_review']).dt.days) / 30, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "0a329262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_f_vars = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'instant_bookable']\n",
    "# train[t_f_vars] = train[t_f_vars].replace({'f': 0, 't': 1})\n",
    "# test[t_f_vars] = test[t_f_vars].replace({'f': 0, 't': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "80f3631b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523      5000.0\n",
       "2067       15.0\n",
       "3129    99998.0\n",
       "4865       14.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top and bottom 0.04%\n",
    "lower_val = np.percentile(train[['price']], 0.04)\n",
    "upper_val = np.percentile(train[['price']], 99.96)\n",
    "\n",
    "outliers_idx = train[(train['price'] >= upper_val) | (train['price'] <= lower_val)].index\n",
    "\n",
    "train_clean = train.drop(outliers_idx).reset_index(drop=True)\n",
    "test_clean = test.copy()\n",
    "\n",
    "train.iloc[outliers_idx, :]['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75484ac",
   "metadata": {},
   "source": [
    "### Clean/Transform Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1604094",
   "metadata": {},
   "source": [
    "*Check poly terms*\n",
    "\n",
    "lat/long second order\n",
    "select certain neighbourhood - northside, west_town, lakeview (+/-)\n",
    "host_listing_count/host_total_listing_count\n",
    "np.log(price) (can or not)\n",
    "\n",
    "reviews_per_month fillna with median \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e197cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_shared(row):\n",
    "    if 'shared' in str(row['bathrooms_text']):\n",
    "        row['bathrooms_shared'] = \"t\"\n",
    "    \n",
    "    elif pd.isna(row['bathrooms_text']):\n",
    "        if 'Shared' in row['room_type']:\n",
    "            row['bathrooms_shared'] = \"t\"              \n",
    "        else:\n",
    "            row['bathrooms_shared'] = \"f\"\n",
    "                           \n",
    "    else: row['bathrooms_shared'] = \"f\"\n",
    "                           \n",
    "    return row\n",
    "                           \n",
    "    \n",
    "\n",
    "# def clean_hoods(row):\n",
    "#     if row.loc['neighbourhood_cleansed'] in other_hoods or row.loc['neighbourhood_cleansed'] in test_only_hoods:\n",
    "#         row['neighbourhood_grouped'] = 'Other'\n",
    "        \n",
    "#     else:    \n",
    "#         row['neighbourhood_grouped'] = row.loc['neighbourhood_cleansed']\n",
    "        \n",
    "#     return row\n",
    "       \n",
    "    \n",
    "def clean_rooms(row):    \n",
    "    if row.loc['room_type'] == 'Hotel room':\n",
    "        row['room_type'] = 'Private room'\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "neighbourhood_counts = train_clean['neighbourhood_cleansed'].value_counts()\n",
    "\n",
    "other_hoods = [i for i in neighbourhood_counts.index if neighbourhood_counts[i] < 100]\n",
    "\n",
    "test_only_hoods = [i for i in test_clean['neighbourhood_cleansed'].unique() \n",
    "                   if i not in neighbourhood_counts \n",
    "                   and i != 'Other']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b24d9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train_clean.apply(is_shared, axis=1)\n",
    "test_clean = test_clean.apply(is_shared, axis=1)\n",
    "\n",
    "train_clean = train_clean.apply(clean_hoods, axis=1)\n",
    "test_clean = test_clean.apply(clean_hoods, axis=1)\n",
    "\n",
    "train_clean = train_clean.apply(clean_rooms, axis=1)\n",
    "test_clean = test_clean.apply(clean_rooms, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e1ca9036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def clean_host_listing(row):\n",
    "#     if row > 80:\n",
    "#         row = None\n",
    "#     return row\n",
    "\n",
    "\n",
    "# train_clean['calculated_host_listings_count'] = train_clean['calculated_host_listings_count'].apply(clean_host_listing)\n",
    "# test_clean['calculated_host_listings_count'] = test_clean['calculated_host_listings_count'].apply(clean_host_listing)\n",
    "\n",
    "# train_clean['calculated_host_listings_count'].fillna(train_clean['calculated_host_listings_count'].median())\n",
    "# test_clean['calculated_host_listings_count'].fillna(test_clean['calculated_host_listings_count'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9308f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train_clean.apply(clean_rooms, axis=1)\n",
    "test_clean = test_clean.apply(clean_rooms, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "02f8da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hood_df = pd.DataFrame(index=train_clean['neighbourhood_cleansed'].unique())\n",
    "neighbourhood_counts = train_clean['neighbourhood_cleansed'].value_counts()\n",
    "\n",
    "all_mean = train_clean.groupby('neighbourhood_cleansed')['price'].mean()\n",
    "all_std = train_clean.groupby('neighbourhood_cleansed')['price'].std()\n",
    "\n",
    "hood_df = pd.concat([hood_df, all_mean, all_std], axis=1)\n",
    "hood_df.columns = ['mean_price', 'std_price']\n",
    "hood_df.sort_values('std_price', inplace=True)\n",
    "hood_df.dropna(inplace=True)\n",
    "hood_df = hood_df.merge(neighbourhood_counts, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "large_std_list = hood_df[hood_df['std_price'] > 175].index.tolist()\n",
    "\n",
    "hood_df.sort_values('std_price')\n",
    "filtered_df = hood_df[((hood_df['std_price'] < 40) | (hood_df['neighbourhood_cleansed'] > 100)) & (hood_df['neighbourhood_cleansed'] > 20)]                             \n",
    "keep_hoods = list(filtered_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "fb370a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other              1483\n",
       "Near North Side     637\n",
       "West Town           482\n",
       "Lake View           355\n",
       "Near West Side      338\n",
       "Logan Square        261\n",
       "Loop                252\n",
       "Lincoln Park        174\n",
       "Near South Side     152\n",
       "Lower West Side     135\n",
       "Uptown              111\n",
       "Woodlawn            111\n",
       "Edgewater           111\n",
       "Irving Park         109\n",
       "Bridgeport          107\n",
       "Avondale            106\n",
       "New City             39\n",
       "South Lawndale       33\n",
       "Name: neighbourhood_grouped, dtype: int64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_hoods(row):\n",
    "    if row.loc['neighbourhood_cleansed'] not in keep_hoods:\n",
    "        row['neighbourhood_grouped'] = 'Other'\n",
    "        \n",
    "    else:    \n",
    "        row['neighbourhood_grouped'] = row.loc['neighbourhood_cleansed']\n",
    "        \n",
    "    return row\n",
    "\n",
    "train_clean = train_clean.apply(clean_hoods, axis=1)\n",
    "train_clean['neighbourhood_grouped'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "da18ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_hoods = train_clean['neighbourhood_grouped'].unique()\n",
    "\n",
    "def test_consistent_hoods(row):\n",
    "    if row not in avail_hoods:\n",
    "        row = 'Other'       \n",
    "    return row\n",
    "\n",
    "test_clean['neighbourhood_grouped'] = test_clean['neighbourhood_cleansed'].apply(test_consistent_hoods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1e62ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_remove = ['room', 'private', 'shared', 'entire', ' in', ' room', ' private', ' shared', ' entire', ' in',]\n",
    "\n",
    "\n",
    "def remove_words(text):\n",
    "    text=text.lower()\n",
    "    for word in words_to_remove:\n",
    "        word = word.lower()\n",
    "        text = text.replace(word, '')\n",
    "    return text.strip()\n",
    "\n",
    "train_clean['property_type_cleansed'] = train_clean['property_type'].apply(remove_words)\n",
    "test_clean['property_type_cleansed'] = test_clean['property_type'].apply(remove_words)\n",
    "\n",
    "\n",
    "property_counts = train_clean['property_type_cleansed'].value_counts()\n",
    "keep = [i for i in property_counts.index if property_counts[i] > 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "679ba33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rental unit           2987\n",
       "home                   734\n",
       "condo                  562\n",
       "serviced apartment     164\n",
       "guest suite            102\n",
       "hotel                  100\n",
       "townhouse               94\n",
       "loft                    58\n",
       "bed and breakfast       50\n",
       "boutique hotel          40\n",
       "guesthouse              40\n",
       "Other                   39\n",
       "bungalow                26\n",
       "Name: property_type_cleansed, dtype: int64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_property(row):\n",
    "    if row not in keep:\n",
    "        row = 'Other'\n",
    "        \n",
    "    return row\n",
    "\n",
    "\n",
    "train_clean['property_type_cleansed'] = train_clean['property_type_cleansed'].apply(clean_property)\n",
    "test_clean['property_type_cleansed'] = test_clean['property_type_cleansed'].apply(clean_property)\n",
    "\n",
    "train_clean['property_type_cleansed'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b6b42532",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_lim = np.percentile(train_clean[['minimum_nights']], 99.9)\n",
    "outliers_idx = train_clean[train_clean['minimum_nights'] >= upper_lim].index\n",
    "\n",
    "train_clean = train_clean.drop(outliers_idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "6fffc836",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['review_scores_avg'] = np.mean(train_clean[['review_scores_rating', 'review_scores_value', 'review_scores_location', 'review_scores_cleanliness']], axis=1)\n",
    "test_clean['review_scores_avg'] = np.mean(test_clean[['review_scores_rating', 'review_scores_value', 'review_scores_location', 'review_scores_cleanliness']], axis=1)\n",
    "\n",
    "train_clean['review_scores_avg'] = train_clean['review_scores_avg'].fillna(value=0)\n",
    "test_clean['review_scores_avg'] = test_clean['review_scores_avg'].fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "0d953fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_filter_2 = train_clean.copy()\n",
    "test_filter_2 = test_clean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb6d2f",
   "metadata": {},
   "source": [
    "### Inspect and impute columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5712a33",
   "metadata": {},
   "source": [
    "#### Model imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "cb65842b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.586773\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "train_filter_temp = train_filter_2.copy()\n",
    "test_filter_temp = test_filter_2.copy()\n",
    "\n",
    "train_filter_temp['host_is_superhost'] = train_filter_2['host_is_superhost'].replace({'f': 0, 't': 1})\n",
    "test_filter_temp['host_is_superhost'] = test_filter_2['host_is_superhost'].replace({'f': 0, 't': 1})\n",
    "\n",
    "superhost_model = smf.logit(formula=\"host_is_superhost ~ calculated_host_listings_count*number_of_reviews_ltm + response_rate\", data=train_filter_temp).fit()\n",
    "\n",
    "train_filter_temp['host_is_superhost_imputed'] = superhost_model.predict(train_filter_temp) > 0.486\n",
    "train_filter_temp['host_is_superhost'].fillna(train_filter_temp['host_is_superhost_imputed'], inplace=True)\n",
    "train_filter_temp.drop(columns=['host_is_superhost_imputed'], inplace=True)\n",
    "\n",
    "test_filter_temp['host_is_superhost_imputed'] = superhost_model.predict(test_filter_temp) > 0.486\n",
    "test_filter_temp['host_is_superhost'].fillna(test_filter_temp['host_is_superhost_imputed'], inplace=True)\n",
    "test_filter_temp.drop(columns=['host_is_superhost_imputed'], inplace=True)\n",
    "\n",
    "\n",
    "train_filter_temp['host_is_superhost'] = train_filter_temp['host_is_superhost'].replace({0:'f', 1:'t'})\n",
    "test_filter_temp['host_is_superhost'] = test_filter_temp['host_is_superhost'].replace({0:'f', 1:'t'})\n",
    "\n",
    "\n",
    "train_filter_2['host_is_superhost'] = train_filter_temp['host_is_superhost']\n",
    "test_filter_2['host_is_superhost'] = test_filter_temp['host_is_superhost']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f59ce391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.192040\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.067415\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "acceptance_model = smf.logit(formula=\"acceptance_rate ~ calculated_host_listings_count + accommodates\", data=train_filter_2).fit()\n",
    "acceptance_model.summary()\n",
    "\n",
    "missing_acceptance = train_filter_2[train_filter_2['acceptance_rate'].isnull()]\n",
    "predicted_acceptance = acceptance_model.predict(missing_acceptance)\n",
    "train_filter_2.loc[missing_acceptance.index, 'acceptance_rate'] = predicted_acceptance\n",
    "\n",
    "\n",
    "response_model = smf.logit(formula=\"response_rate ~ accommodates\", data=train_filter_2).fit()\n",
    "response_model.summary()\n",
    "\n",
    "missing_response = train_filter_2[train_filter_2['response_rate'].isnull()]\n",
    "predicted_response = response_model.predict(missing_response)\n",
    "train_filter_2.loc[missing_response.index, 'response_rate'] = predicted_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed5943",
   "metadata": {},
   "source": [
    "#### Naive imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d5148e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_train = train_filter_2.dropna(how='any')\n",
    "\n",
    "for col in temp_data_train.select_dtypes(include='number').columns:\n",
    "    if train_filter_2.isna().sum()[col] != 0:\n",
    "        train_filter_2[col].fillna(value=train_filter_2[col].median(), inplace=True) \n",
    "\n",
    "train_final = train_filter_2.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "63062b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_test = test_filter_2.dropna(how='any')\n",
    "\n",
    "for col in temp_data_test.select_dtypes(include='number').columns:\n",
    "    if test_filter_2.isna().sum()[col] != 0:\n",
    "        test_filter_2[col].fillna(value=test_filter_2[col].median(), inplace=True)  \n",
    "\n",
    "test_final = test_filter_2.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d152bf",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "64d29d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_sklearn = ['acceptance_rate', 'accommodates', 'availability_30', 'availability_90',\n",
    "                    'bathrooms_num', 'bathrooms_shared', 'beds', \n",
    "                    'calculated_host_listings_count', 'last_review_in_months',\n",
    "                    'host_is_superhost','host_since_in_months', 'id', 'latitude', 'longitude', \n",
    "                    'maximum_nights', 'minimum_nights', \n",
    "                    'neighbourhood_grouped', 'number_of_reviews_ltm', \n",
    "                    'price', 'property_type_cleansed', 'response_rate',  \n",
    "                    'review_scores_avg', 'reviews_per_month', 'room_type',\n",
    "                    'maximum_nights_avg_ntm', 'minimum_nights_avg_ntm',]\n",
    "                    # ,'first_review_in_months', 'last_review_in_months' \n",
    "\n",
    "\n",
    "cols_for_sklearn_test = [name for name in cols_for_sklearn if name != 'price']\n",
    "\n",
    "subset_train = train_final[cols_for_sklearn].copy()\n",
    "subset_test = test_final[cols_for_sklearn_test].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d08522ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = subset_train.drop(columns='price')\n",
    "y_train = np.log(subset_train.price)\n",
    "\n",
    "X_test = subset_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "df33aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test_preprocessed = pd.get_dummies(X_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298ae49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9cbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "2c29fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_type_cols = [name for name in X_train_preprocessed.columns if 'room_type' in name]\n",
    "neighbourhood_groups = [name for name in X_train_preprocessed.columns if 'neighbourhood_grouped' in name]\n",
    "property_groups = [name for name in X_train_preprocessed.columns if 'property' in name]\n",
    "\n",
    "\n",
    "interaction_pairs = [('bathrooms_num', 'bathrooms_shared_t'),\n",
    "                     ('beds', 'accommodates'),\n",
    "                     ('acceptance_rate', 'response_rate'),\n",
    "                     \n",
    "                     ('accommodates', 'availability_30'),\n",
    "                     ('accommodates', 'availability_90'),\n",
    "                     ('acceptance_rate', 'host_is_superhost_t'), \n",
    "                     ('response_rate', 'host_is_superhost_t'),\n",
    "                     \n",
    "                    ('number_of_reviews_ltm', 'review_scores_avg'),\n",
    "                    ('last_review_in_months', 'number_of_reviews_ltm'),\n",
    "                    ('reviews_per_month', 'number_of_reviews_ltm'),\n",
    "                    ('reviews_per_month', 'review_scores_avg'), \n",
    "                    ('review_scores_avg', 'calculated_host_listings_count')] \n",
    "        # room_type*accommodates, room_type*neighbourhood_grouped, room_type*property_type, \n",
    "        # room_type*availability_90, property_type*neighbourhood_grouped        \n",
    "        \n",
    "        \n",
    "\n",
    "for i in room_type_cols:\n",
    "    interaction_pairs.append((i, 'beds'))\n",
    "#     interaction_pairs.append((i, 'availability_30'))\n",
    "    \n",
    "    for j in neighbourhood_groups: \n",
    "        interaction_pairs.append((j, i))\n",
    "    \n",
    "    for k in property_groups:\n",
    "        interaction_pairs.append((i, k))\n",
    "\n",
    "        \n",
    "for i in property_groups:\n",
    "    for j in neighbourhood_groups:\n",
    "        interaction_pairs.append((i, j))\n",
    "\n",
    "        \n",
    "        \n",
    "### ----- ###\n",
    "\n",
    "interaction_cols = []\n",
    "for t in interaction_pairs:\n",
    "    for item in t:\n",
    "        interaction_cols.append(item)\n",
    "        \n",
    "        \n",
    "        \n",
    "interaction_df = pd.DataFrame()\n",
    "interaction_df_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "for pair in interaction_pairs:\n",
    "    interaction_columns = pair\n",
    "    \n",
    "    X_train_interaction_subset = X_train_preprocessed[list(interaction_columns)]\n",
    "    X_test_interaction_subset = X_test_preprocessed[list(interaction_columns)]\n",
    "    \n",
    "    poly_features = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "    interaction_terms_train = poly_features.fit_transform(X_train_interaction_subset)\n",
    "    interaction_terms_test = poly_features.transform(X_test_interaction_subset)\n",
    "    \n",
    "    interaction_column_names = poly_features.get_feature_names_out(input_features=interaction_columns)\n",
    "    \n",
    "    interaction_df_pair = pd.DataFrame(interaction_terms_train, columns=interaction_column_names)\n",
    "    interaction_df_pair_test = pd.DataFrame(interaction_terms_test, columns=interaction_column_names)\n",
    "    \n",
    "\n",
    "    interaction_df = pd.concat([interaction_df, interaction_df_pair], axis=1)\n",
    "    interaction_df_test = pd.concat([interaction_df_test, interaction_df_pair_test], axis=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "2e3286f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = pd.concat([X_train_preprocessed.drop(columns=interaction_cols), interaction_df], axis=1)\n",
    "X_test_processed = pd.concat([X_test_preprocessed.drop(columns=interaction_cols), interaction_df_test], axis=1)        \n",
    "\n",
    "X_train_processed = X_train_processed.loc[:,~X_train_processed.columns.duplicated()].copy()\n",
    "X_train_processed = X_train_processed.reindex(sorted(X_train_processed.columns), axis=1)\n",
    "X_test_processed = X_test_processed.loc[:,~X_test_processed.columns.duplicated()].copy()\n",
    "X_test_processed = X_test_processed.reindex(sorted(X_test_processed.columns), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "1e627456",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed['maximum_nights^2'] = X_train_processed['maximum_nights'] ** 2\n",
    "X_train_processed['maximum_nights^3'] = X_train_processed['maximum_nights'] ** 3\n",
    "X_train_processed['minimum_nights^2'] = X_train_processed['minimum_nights'] ** 2\n",
    "X_train_processed['minimum_nights^3'] = X_train_processed['minimum_nights'] ** 3\n",
    "X_train_processed['longitude^2'] = X_train_processed['longitude'] ** 2\n",
    "X_train_processed['latitude^2'] = X_train_processed['latitude'] ** 2\n",
    "X_train_processed['longitude^3'] = X_train_processed['longitude'] ** 3\n",
    "X_train_processed['latitude^3'] = X_train_processed['latitude'] ** 3\n",
    "X_train_processed['calculated_host_listings_count_log'] = np.log(X_train_processed['calculated_host_listings_count'])\n",
    "X_train_processed['calculated_host_listings_count_log^2'] = np.log(X_train_processed['calculated_host_listings_count'])**2\n",
    "X_train_processed['calculated_host_listings_count_log^3'] = np.log(X_train_processed['calculated_host_listings_count'])**3\n",
    "X_train_processed['reviews_per_month^2'] = X_train_processed['reviews_per_month'] ** 2\n",
    "X_train_processed['number_of_reviews_ltm_root'] = np.sqrt(X_train_processed['number_of_reviews_ltm'])\n",
    "\n",
    "X_test_processed['maximum_nights^2'] = X_test_processed['maximum_nights'] ** 2\n",
    "X_test_processed['maximum_nights^3'] = X_test_processed['maximum_nights'] ** 3\n",
    "X_test_processed['minimum_nights^2'] = X_test_processed['minimum_nights'] ** 2\n",
    "X_test_processed['minimum_nights^3'] = X_test_processed['minimum_nights'] ** 3\n",
    "X_test_processed['longitude^2'] = X_test_processed['longitude'] ** 2\n",
    "X_test_processed['latitude^2'] = X_test_processed['latitude'] ** 2\n",
    "X_test_processed['longitude^3'] = X_test_processed['longitude'] ** 3\n",
    "X_test_processed['latitude^3'] = X_test_processed['latitude'] ** 3\n",
    "X_test_processed['calculated_host_listings_count_log'] = np.log(X_test_processed['calculated_host_listings_count'])\n",
    "X_test_processed['calculated_host_listings_count_log^2'] = np.log(X_test_processed['calculated_host_listings_count'])**2\n",
    "X_test_processed['calculated_host_listings_count_log^3'] = np.log(X_test_processed['calculated_host_listings_count'])**3\n",
    "X_test_processed['reviews_per_month^2'] = X_test_processed['reviews_per_month'] ** 2\n",
    "X_test_processed['number_of_reviews_ltm_root'] = np.sqrt(X_test_processed['number_of_reviews_ltm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "65a4284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X_train.select_dtypes(exclude='number').columns\n",
    "cat_dummy_dict = {}\n",
    "\n",
    "for cat in cat_cols:\n",
    "    curr_cat_dummies = pd.get_dummies(X_train[cat], prefix=cat, drop_first=True).columns\n",
    "    cat_dummy_dict[cat] = curr_cat_dummies\n",
    "\n",
    "    \n",
    "possible_cat_cat = []\n",
    "for k in cat_dummy_dict.keys():\n",
    "    dummy_list = list(cat_dummy_dict[k])\n",
    "    \n",
    "    for j in cat_dummy_dict.keys():\n",
    "        dummy_list2 = list(cat_dummy_dict[j])\n",
    "        \n",
    "        \n",
    "        for dummy in dummy_list:\n",
    "            for dummy2 in dummy_list2:\n",
    "    \n",
    "                if k != j and dummy != dummy2:\n",
    "                    final_dummy = dummy + ' ' + dummy2\n",
    "                    possible_cat_cat.append(final_dummy)\n",
    "\n",
    "                    \n",
    "plain_dummies = list(pd.get_dummies(X_train[cat_cols], drop_first=True).columns)\n",
    "\n",
    "binary_cols = plain_dummies + possible_cat_cat\n",
    "\n",
    "new_cat_cols = [col for col in X_train_processed.columns if col in binary_cols]\n",
    "new_num_cols = [col for col in X_train_processed.columns if col not in new_cat_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "4fd0b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train_processed[new_num_cols])\n",
    "\n",
    "train_scaled = sc.transform(X_train_processed[new_num_cols])\n",
    "test_scaled = sc.transform(X_test_processed[new_num_cols]) \n",
    "\n",
    "X_train_scaled = pd.DataFrame(train_scaled, columns=new_num_cols)\n",
    "X_test_scaled = pd.DataFrame(test_scaled, columns=new_num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5b835674",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed[new_num_cols] = X_train_scaled\n",
    "X_test_processed[new_num_cols] = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "270f819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train_processed.drop(columns=['calculated_host_listings_count'])\n",
    "X_test_final = X_test_processed.drop(columns=['calculated_host_listings_count'])\n",
    "\n",
    "X_train_final = X_train_processed.copy()\n",
    "X_test_final = X_test_processed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "7c951889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.756\n",
      "Diff rmse-mae: 74.6614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train_final, y_train)\n",
    "\n",
    "y_pred_train = np.exp(lrm.predict(X_train_final))*1.05\n",
    "curr_rmse = mean_squared_error(train_final.price, y_pred_train, squared = False) \n",
    "curr_mae = mean_absolute_error(train_final.price, y_pred_train) \n",
    "\n",
    "print(round(curr_rmse, 4))\n",
    "print(\"Diff rmse-mae:\", round(curr_rmse-curr_mae, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7022e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = pd.DataFrame(np.exp(lrm.predict(X_test_final))*1.05, columns=['predicted'])\n",
    "predicted_values = predicted_values.merge(test_final['id'], left_index=True, right_index=True).set_index('id').rename(columns={0:'predicted'})\n",
    "predicted_values\n",
    "\n",
    "# predicted_values.to_csv('liner_model_7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b448485",
   "metadata": {},
   "source": [
    "##### Log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0356e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 125.0812\n",
    "# Diff rmse-mae: 72.5318\n",
    "\n",
    "#### mean for review scores avg and fill na with 0\n",
    "### 124.7993\n",
    "### Diff rmse-mae: 72.237\n",
    "\n",
    "## mean for review scores avg and fill na with mean\n",
    "# 124.8374\n",
    "# Diff rmse-mae: 72.2813\n",
    "\n",
    "## mean for review scores avg and fill na with 1\n",
    "# 124.8009\n",
    "# Diff rmse-mae: 72.2385\n",
    "\n",
    "\n",
    "#### Property types from >5 to > 10\n",
    "### 127.7623\n",
    "### Diff rmse-mae: 74.6855\n",
    "# Test rmse 119.39\n",
    "\n",
    "\n",
    "## Only drop upper outliers for price\n",
    "# 127.9261\n",
    "# Diff rmse-mae: 74.8203\n",
    "# Test 119.51\n",
    "\n",
    "## price percentile to 0.05\n",
    "# Test 119.41\n",
    "\n",
    "\n",
    "## interact lising count with review average and listing count with superhost\n",
    "# 127.7953\n",
    "# Diff rmse-mae: 74.7491\n",
    "\n",
    "## just interact lising count with review average, no listing count and superhost\n",
    "# 127.7801\n",
    "# Diff rmse-mae: 74.7144\n",
    "\n",
    "## raise hood count from 100 to 120 \n",
    "# 128.5801\n",
    "# Diff rmse-mae: 74.8061\n",
    "# test Rmse 119.43\n",
    "\n",
    "#### Raise minimum neighbourhood count to 20\n",
    "### 127.756\n",
    "### Diff rmse-mae: 74.6614\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10ad62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "efae31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals = np.exp(y_train) - y_pred_train\n",
    "\n",
    "# # Calculate the standard deviation of residuals\n",
    "# residual_std = np.std(residuals)\n",
    "\n",
    "# # Calculate studentized residuals\n",
    "# studentized_residuals = residuals / residual_std\n",
    "\n",
    "# # Convert to DataFrame for easy manipulation\n",
    "# data = {'residuals': residuals, 'studentized_residuals': studentized_residuals}\n",
    "# stud_res_df = pd.DataFrame(data)\n",
    "# stud_res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c715e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "\n",
    "# N = train_final.shape[0]\n",
    "# p = ridgeCV.coef_.shape[0]\n",
    "# alpha = 0.05\n",
    "\n",
    "# critic_val = stats.t.ppf(1 - alpha / 2, N - p - 1)\n",
    "\n",
    "# outliers_idx = np.array(stud_res_df[stud_res_df.studentized_residuals > critic_val].index)\n",
    "\n",
    "# train_final.iloc[outliers_idx, :]['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "287f48fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute hat matrix\n",
    "# H = X_train_processed.dot(np.linalg.pinv(X_train_processed.T.dot(X_train_processed)).dot(X_train_processed.T))\n",
    "\n",
    "# # Get diagonal elements of hat matrix as leverage\n",
    "# leverage = np.diag(H)\n",
    "\n",
    "# # Calculate average leverage\n",
    "# avg_leverage = np.mean(leverage)\n",
    "\n",
    "# # # Find indices of observations with leverage greater than 4 times the average leverage\n",
    "# high_leverage_indices = np.where(leverage >= 4*avg_leverage)\n",
    "\n",
    "# # avg_leverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ef8674cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_inf = np.intersect1d(outliers_idx, high_leverage_indices)\n",
    "# train_final.iloc[high_inf, :]['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e95bac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_clean = X_train_final.drop(high_inf).reset_index(drop=True)\n",
    "# y_train_clean = y_train.drop(high_inf).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "30964e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas = 10**np.linspace(1, 0, 100)\n",
    "\n",
    "# final_model = RidgeCV(alphas=alphas, cv=10, scoring='neg_root_mean_squared_error')\n",
    "# final_model.fit(X_train_clean, y_train_clean)\n",
    "# optimal_alpha = final_model.alpha_\n",
    "# print(optimal_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3814c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_train_pred = np.exp(final_model.predict(X_train_clean))*1.05\n",
    "# rmse = mean_squared_error(y_train_clean, clean_train_pred, squared = False) \n",
    "# mae = mean_absolute_error(y_train_clean, clean_train_pred) \n",
    "\n",
    "# rmse, mae, rmse-mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dddb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec79a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a673ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
