{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dbd80240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0ac82fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('datasets/train_classification.csv')\n",
    "raw_test = pd.read_csv('datasets/test_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d0493a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_train.copy()\n",
    "test = raw_test.copy()\n",
    "\n",
    "\n",
    "train['acceptance_rate'] = train['host_acceptance_rate'].str.replace('%', '').astype(float) / 100\n",
    "train['response_rate'] = train['host_response_rate'].str.replace('%', '').astype(float) / 100\n",
    "\n",
    "test['acceptance_rate'] = test['host_acceptance_rate'].str.replace('%', '').astype(float) / 100\n",
    "test['response_rate'] = test['host_response_rate'].str.replace('%', '').astype(float) / 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8ba25018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     3846\n",
       "12.0     433\n",
       "24.0     230\n",
       "72.0      51\n",
       "Name: response_time, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_time_dict = {'within an hour': 1, 'within a few hours': 12, 'within a day': 24, 'a few days or more': 72}\n",
    "\n",
    "def replace_response_time(row):\n",
    "    if pd.notna(row):\n",
    "        return response_time_dict.get(row)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "train['response_time'] = train['host_response_time'].apply(replace_response_time)\n",
    "test['response_time'] = test['host_response_time'].apply(replace_response_time)\n",
    "\n",
    "\n",
    "train['response_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4a1c096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['host_acceptance_rate', 'host_response_rate'], inplace=True)\n",
    "test.drop(columns=['host_acceptance_rate', 'host_response_rate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3cc94a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns\n",
    "def strip_date(row):\n",
    "    if isinstance(row, str):\n",
    "        row = datetime.strptime(row, '%Y-%m-%d').date()\n",
    "    return row\n",
    "\n",
    "# Apply date conversion to train dataset\n",
    "train['host_since'] = train['host_since'].apply(strip_date)\n",
    "train['first_review'] = train['first_review'].apply(strip_date)\n",
    "train['last_review'] = train['last_review'].apply(strip_date)\n",
    "\n",
    "# Apply date conversion to test dataset\n",
    "test['host_since'] = test['host_since'].apply(strip_date)\n",
    "test['first_review'] = test['first_review'].apply(strip_date)\n",
    "test['last_review'] = test['last_review'].apply(strip_date)\n",
    "\n",
    "\n",
    "# Create columns for individual aspects of date \n",
    "train['host_since_year'] = train['host_since'].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "train['host_since_month'] = train['host_since'].apply(lambda x: x.month if pd.notnull(x) else None)\n",
    "train['host_since_day'] = train['host_since'].apply(lambda x: x.day if pd.notnull(x) else None)\n",
    "\n",
    "train['first_review_year'] = train['first_review'].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "train['first_review_month'] = train['first_review'].apply(lambda x: x.month if pd.notnull(x) else None)\n",
    "train['first_review_day'] = train['first_review'].apply(lambda x: x.day if pd.notnull(x) else None)\n",
    "\n",
    "train['last_review_year'] = train['last_review'].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "train['last_review_month'] = train['last_review'].apply(lambda x: x.month if pd.notnull(x) else None)\n",
    "train['last_review_day'] = train['last_review'].apply(lambda x: x.day if pd.notnull(x) else None)\n",
    "\n",
    "\n",
    "test['host_since_year'] = test['host_since'].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "test['host_since_month'] = test['host_since'].apply(lambda x: x.month if pd.notnull(x) else None)\n",
    "test['host_since_day'] = test['host_since'].apply(lambda x: x.day if pd.notnull(x) else None)\n",
    "\n",
    "test['first_review_year'] = test['first_review'].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "test['first_review_month'] = test['first_review'].apply(lambda x: x.month if pd.notnull(x) else None)\n",
    "test['first_review_day'] = test['first_review'].apply(lambda x: x.day if pd.notnull(x) else None)\n",
    "\n",
    "test['last_review_year'] = test['last_review'].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "test['last_review_month'] = test['last_review'].apply(lambda x: x.month if pd.notnull(x) else None)\n",
    "test['last_review_day'] = test['last_review'].apply(lambda x: x.day if pd.notnull(x) else None)\n",
    "\n",
    "\n",
    "# Calculate months since various dates for train dataset\n",
    "train['host_since_in_months'] = round(((datetime.now().date() - train['host_since']).dt.days) / 30, 2)\n",
    "train['first_review_in_months'] = round(((datetime.now().date() - train['first_review']).dt.days) / 30, 2)\n",
    "train['last_review_in_months'] = round(((datetime.now().date() - train['last_review']).dt.days) / 30, 2)\n",
    "\n",
    "# Calculate months since various dates for test dataset\n",
    "test['host_since_in_months'] = round(((datetime.now().date() - test['host_since']).dt.days) / 30,  2)\n",
    "test['first_review_in_months'] = round(((datetime.now().date() - test['first_review']).dt.days) / 30, 2)\n",
    "test['last_review_in_months'] = round(((datetime.now().date() - test['last_review']).dt.days) / 30, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "73303b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_f_vars = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'instant_bookable']\n",
    "# t_f_vars_test = ['host_has_profile_pic', 'host_identity_verified', 'has_availability', 'instant_bookable']\n",
    "\n",
    "\n",
    "# train[t_f_vars] = train[t_f_vars].replace({'f': 0, 't': 1})\n",
    "# test[t_f_vars_test] = test[t_f_vars_test].replace({'f': 0, 't': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "94de2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train.copy() \n",
    "test_clean = test.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de0269",
   "metadata": {},
   "source": [
    "### Clean/Transform Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "629108ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neighbourhood_counts = train_clean['neighbourhood_cleansed'].value_counts()  \n",
    "    \n",
    "def clean_rooms(row):    \n",
    "    if row.loc['room_type'] == 'Hotel room':\n",
    "        row['room_type'] = 'Private room'\n",
    "        \n",
    "    if row.loc['room_type'] == 'Shared room':\n",
    "        row['room_type'] = 'Entire home/apt'\n",
    "        \n",
    "    return row\n",
    "\n",
    "\n",
    " \n",
    "test_only_hoods = [i for i in test_clean['neighbourhood_cleansed'].unique() \n",
    "                   if i not in neighbourhood_counts \n",
    "                   and i != 'Other']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "77c0663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['host_verifications_list'] = train_clean['host_verifications'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(', '))\n",
    "test_clean['host_verifications_list'] = test_clean['host_verifications'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(', '))\n",
    "\n",
    "train_clean['num_verifications']  = train_clean['host_verifications_list'].apply(len)\n",
    "test_clean['num_verifications']  = test_clean['host_verifications_list'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "39559c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['phone_verification']  = train_clean['host_verifications_list'].apply(lambda x: 1 if 'phone' in x else 0)\n",
    "train_clean['email_verification']  = train_clean['host_verifications_list'].apply(lambda x: 1 if 'email' in x else 0)\n",
    "train_clean['work_email_verification'] = train_clean['host_verifications_list'].apply(lambda x: 1 if 'work_email' in x else 0)\n",
    "train_clean['any_email_verification'] = train_clean['host_verifications_list'].apply(lambda x: 1 if 'work_email' in x or 'email' in x else 0)\n",
    "# print(train_clean['num_verifications'].value_counts(), '\\n')\n",
    "\n",
    "test_clean['phone_verification']  = test_clean['host_verifications_list'].apply(lambda x: 1 if 'phone' in x else 0)\n",
    "test_clean['email_verification']  = test_clean['host_verifications_list'].apply(lambda x: 1 if 'email' in x else 0)\n",
    "test_clean['work_email_verification'] = test_clean['host_verifications_list'].apply(lambda x: 1 if 'work_email' in x else 0)\n",
    "test_clean['any_email_verification'] = test_clean['host_verifications_list'].apply(lambda x: 1 if 'work_email' in x or 'email' in x else 0)\n",
    "# print(train_clean['num_verifications'].value_counts(), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b4047e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 14, 30, 60, 90, 180, 365, float('inf')]\n",
    "labels = ['0-14', '14-30', '30-60', '60-90', '90-180', '180-365', '365<']\n",
    "\n",
    "train_clean['max_nights_cats'], max_bins = pd.cut(train_clean.maximum_nights, bins=bins, labels=labels, retbins=True, right=False, include_lowest=True)\n",
    "test_clean['max_nights_cats'] = pd.cut(test_clean.maximum_nights, bins=max_bins, labels=labels, right=False, include_lowest=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cfb773a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       44.0\n",
       "1        3.0\n",
       "2       51.0\n",
       "3       14.0\n",
       "4       19.0\n",
       "        ... \n",
       "3319    22.0\n",
       "3320    12.0\n",
       "3321    12.0\n",
       "3322     8.0\n",
       "3323     2.0\n",
       "Name: calculated_host_listings_count, Length: 3324, dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for host listing count outliers (>80) set to median\n",
    "def clean_host_listing(row):\n",
    "    if row > 80:\n",
    "        row = None\n",
    "    return row\n",
    "\n",
    "\n",
    "train_clean['calculated_host_listings_count'] = train_clean['calculated_host_listings_count'].apply(clean_host_listing)\n",
    "test_clean['calculated_host_listings_count'] = test_clean['calculated_host_listings_count'].apply(clean_host_listing)\n",
    "\n",
    "train_clean['calculated_host_listings_count'].fillna(train_clean['calculated_host_listings_count'].median())\n",
    "test_clean['calculated_host_listings_count'].fillna(test_clean['calculated_host_listings_count'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b311ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['reviews_per_listing'] = train_clean['number_of_reviews']/train_clean['calculated_host_listings_count']\n",
    "train_clean['reviews_per_month'] = train_clean['number_of_reviews']/train_clean['host_since_in_months']\n",
    "train_clean['reviews_per_listing_per_month'] = train_clean['reviews_per_listing']/train_clean['host_since_in_months']\n",
    "\n",
    "test_clean['reviews_per_listing'] = test_clean['number_of_reviews']/test_clean['calculated_host_listings_count']\n",
    "test_clean['reviews_per_month'] = test_clean['number_of_reviews']/test_clean['host_since_in_months']\n",
    "test_clean['reviews_per_listing_per_month'] = test_clean['reviews_per_listing']/test_clean['host_since_in_months']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc17ae87",
   "metadata": {},
   "source": [
    "#### Sophisticated Cleaning of Neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "37085991",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_hoods = []\n",
    "for i in neighbourhood_counts.index:\n",
    "    if neighbourhood_counts[i] < 150:\n",
    "        other_hoods.append(i)         \n",
    "    \n",
    "def clean_hoods(row):\n",
    "    if row.loc['neighbourhood_cleansed'] in other_hoods or row.loc['neighbourhood_cleansed'] in test_only_hoods:\n",
    "        row['neighbourhood_grouped'] = 'Other'\n",
    "        \n",
    "    else:    \n",
    "        row['neighbourhood_grouped'] = row.loc['neighbourhood_cleansed']\n",
    "        \n",
    "    return row\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ec7248aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train_clean.apply(clean_hoods, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2c169eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hood_df = pd.DataFrame()\n",
    "hood_df.index = train_clean['neighbourhood_grouped'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "048e3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_hoods = train_clean['neighbourhood_grouped'].unique()\n",
    "\n",
    "def test_consistent_hoods(row):\n",
    "    if row not in avail_hoods:\n",
    "        row = 'Other'       \n",
    "    return row\n",
    "\n",
    "test_clean['neighbourhood_grouped'] = test_clean['neighbourhood_cleansed'].apply(test_consistent_hoods)\n",
    "# test_clean['neighbourhood_grouped'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "715bbd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter_2 = train_clean.copy() #.drop(columns=grab_vars)\n",
    "test_filter_2 = test_clean.copy() #.drop(columns=grab_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "31b1a1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmal\\AppData\\Local\\Temp\\ipykernel_13308\\162466571.py:13: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  review_corrs = train_final[review_vars].corr()\n"
     ]
    }
   ],
   "source": [
    "temp_data_train = train_filter_2.dropna(how='any')\n",
    "\n",
    "for col in temp_data_train.select_dtypes(include='number').columns:\n",
    "    if train_filter_2.isna().sum()[col] != 0:\n",
    "        train_filter_2[col].fillna(value=train_filter_2[col].median(), inplace=True) \n",
    "\n",
    "train_final = train_filter_2.copy()\n",
    "\n",
    "value_counts = train_final.isna().sum()\n",
    "value_counts[value_counts != 0]\n",
    "\n",
    "review_vars = [name for name in train_final.columns if 'review' in name]\n",
    "review_corrs = train_final[review_vars].corr()\n",
    "# review_corrs[(review_corrs != 1.0) & (review_corrs > 0.7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f65d5c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_test = test_filter_2.dropna(how='any')\n",
    "\n",
    "for col in temp_data_test.select_dtypes(include='number').columns:\n",
    "    if test_filter_2.isna().sum()[col] != 0:\n",
    "        test_filter_2[col].fillna(value=test_filter_2[col].median(), inplace=True)  \n",
    "\n",
    "test_final = test_filter_2.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fe36a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final['accommodates_bins'], bins = pd.cut(train_final['accommodates'], retbins=True, bins=6)\n",
    "test_final['accommodates_bins'] = pd.cut(test['accommodates'], bins=bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "12a6d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final['latitude_bins'], lat_bins = pd.cut(train_final['latitude'], retbins=True, bins=12)\n",
    "train_final['longitude_bins'], long_bins = pd.cut(train_final['longitude'], retbins=True, bins=12)\n",
    "\n",
    "test_final['latitude_bins'] = pd.cut(test['accommodates'], bins=lat_bins)\n",
    "test_final['longitude_bins'] = pd.cut(test['accommodates'], bins=long_bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f4a7e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final['accommodates_root'] = np.sqrt(train_final['accommodates'])\n",
    "test_final['accommodates_root'] = np.sqrt(test_final['accommodates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a8569",
   "metadata": {},
   "source": [
    "## **Test Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "26056e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_us = ['Italy', 'Tulum, Mexico', 'Toronto, Canada', 'United Kingdom', 'Cartagena, Colombia']\n",
    "# non_us.append('United States')\n",
    "\n",
    "# host_locals_count = train_final['host_location'].value_counts() #.drop(non_us)\n",
    "# major_host_locals = host_locals_count[host_locals_count < 3]\n",
    "# major_host_locals = list(major_host_locals.index)\n",
    "\n",
    "# temp_host_data = train_final[~train_final['host_location'].isin(non_us)]\n",
    "# # temp_host_data = temp_host_data[temp_host_data['host_location'] != 'Chicago, IL']\n",
    "\n",
    "# print(temp_host_data['latitude'].max(), temp_host_data['latitude'].min(), temp_host_data['longitude'].max(), temp_host_data['longitude'].min())\n",
    "\n",
    "# max_diff = max([temp_host_data['latitude'].max()-temp_host_data['latitude'].min(), temp_host_data['longitude'].min()-temp_host_data['longitude'].max()])\n",
    "# print(max_diff)\n",
    "# max_diff_half = max_diff/2\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "519a295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(data=train_final, x='neighbourhood_grouped', y='host_is_superhost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a2916",
   "metadata": {},
   "source": [
    "### Function to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1a2c49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(train_final, formula, last_rmse, last_mae, best_rmse, best_mae, best_diff, best_rmse_formula, best_mae_formula):\n",
    "    try:\n",
    "        model = smf.ols(formula=formula, data=train_final).fit()\n",
    "        trying_pred = model.predict(train_final)\n",
    "        trying_pred = np.exp(trying_pred)\n",
    "        rmse = mean_squared_error(train_final['price'], trying_pred, squared=False)\n",
    "        mae = mean_absolute_error(train_final['price'], trying_pred)\n",
    "        mae_rmse_diff = rmse - mae \n",
    "\n",
    "        difference_rmse = (rmse - last_rmse)\n",
    "        difference_mae = (mae - last_mae)   \n",
    "\n",
    "        if difference_rmse > 0:\n",
    "            print(f'''RMSE: {round(rmse, 3)}\\nMAE: {round(mae, 3)}\\nDiff: {mae_rmse_diff}\\n''')\n",
    "            print(f\"RMSE Increase by {difference_rmse}\")\n",
    "\n",
    "        elif difference_rmse < 0:\n",
    "            print(f'''RMSE: {round(rmse, 3)}\\nMAE: {round(mae, 3)}\\nDiff: {mae_rmse_diff}\\n''')\n",
    "            print(f\"RMSE Decreased: {difference_rmse}\")\n",
    "        else: \n",
    "            print(f'''\\t- No change -\\nRMSE: {round(rmse, 3)}\\nMAE: {round(mae, 3)}\\nDiff: {mae_rmse_diff}\\n''')\n",
    "\n",
    "        if rmse <= best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_rmse_formula = formula\n",
    "            print(f\"Best RMSE!\")\n",
    "\n",
    "        if mae <= best_mae:\n",
    "            best_mae = mae\n",
    "            best_mae_formula = formula\n",
    "            print(f\"Best MAE!\")    \n",
    "\n",
    "        if mae_rmse_diff <= best_diff:\n",
    "            best_diff = mae_rmse_diff\n",
    "            print(f\"Best Diff!\\t {best_diff}\")\n",
    "\n",
    "        print(f\"\\nlast rmse {last_rmse}; last mae {last_mae}\")    \n",
    "        if best_rmse != rmse:\n",
    "            print(f\"Best RMSE {best_rmse}; Best MAE {best_mae}\")    \n",
    "\n",
    "        last_rmse = rmse\n",
    "        last_mae = mae    \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "972c92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final['review_scores_avg'] = np.sum(train_final[['review_scores_rating', 'review_scores_value', 'review_scores_location', 'review_scores_cleanliness']], axis=1)\n",
    "test_final['review_scores_avg'] = np.sum(test_final[['review_scores_rating', 'review_scores_value', 'review_scores_location', 'review_scores_cleanliness']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "80160566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_final['host_is_superhost'] = train_final['host_is_superhost'].replace({\"f\":0, \"t\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d9280469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.461256\n",
      "         Iterations 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmal\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2383: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "C:\\Users\\emmal\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2383: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>host_is_superhost</td> <th>  No. Observations:  </th>  <td>  4977</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  4946</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>        <th>  Df Model:          </th>  <td>    30</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 08 Mar 2024</td>  <th>  Pseudo R-squ.:     </th>  <td>0.3273</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:53:34</td>      <th>  Log-Likelihood:    </th> <td> -2295.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>        <th>  LL-Null:           </th> <td> -3412.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>     <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                   <td></td>                                      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                           <td>   -4.4402</td> <td>    1.437</td> <td>   -3.090</td> <td> 0.002</td> <td>   -7.257</td> <td>   -1.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(response_time)[T.12.0]</th>                                            <td>   -0.0719</td> <td>    0.125</td> <td>   -0.576</td> <td> 0.565</td> <td>   -0.317</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(response_time)[T.24.0]</th>                                            <td>   -0.6064</td> <td>    0.200</td> <td>   -3.039</td> <td> 0.002</td> <td>   -0.997</td> <td>   -0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(response_time)[T.72.0]</th>                                            <td>   -2.0913</td> <td>    1.082</td> <td>   -1.933</td> <td> 0.053</td> <td>   -4.212</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(neighbourhood_grouped, Treatment('West Town'))[T.Lake View]</th>       <td>    0.2990</td> <td>    0.179</td> <td>    1.674</td> <td> 0.094</td> <td>   -0.051</td> <td>    0.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(neighbourhood_grouped, Treatment('West Town'))[T.Lincoln Park]</th>    <td>    0.4459</td> <td>    0.223</td> <td>    1.998</td> <td> 0.046</td> <td>    0.009</td> <td>    0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(neighbourhood_grouped, Treatment('West Town'))[T.Logan Square]</th>    <td>   -0.1232</td> <td>    0.197</td> <td>   -0.624</td> <td> 0.533</td> <td>   -0.510</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(neighbourhood_grouped, Treatment('West Town'))[T.Loop]</th>            <td>    0.3815</td> <td>    0.236</td> <td>    1.613</td> <td> 0.107</td> <td>   -0.082</td> <td>    0.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(neighbourhood_grouped, Treatment('West Town'))[T.Near North Side]</th> <td>   -0.2272</td> <td>    0.166</td> <td>   -1.368</td> <td> 0.171</td> <td>   -0.553</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(neighbourhood_grouped, Treatment('West Town'))[T.Near South Side]</th> <td>    0.7461</td> <td>    0.248</td> <td>    3.005</td> <td> 0.003</td> <td>    0.260</td> <td>    1.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(neighbourhood_grouped, Treatment('West Town'))[T.Near West Side]</th>  <td>   -0.1225</td> <td>    0.193</td> <td>   -0.636</td> <td> 0.525</td> <td>   -0.500</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(neighbourhood_grouped, Treatment('West Town'))[T.Other]</th>           <td>    0.0054</td> <td>    0.123</td> <td>    0.044</td> <td> 0.965</td> <td>   -0.236</td> <td>    0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(host_since_in_months ** 2)</th>                                        <td>-5.026e-06</td> <td> 2.18e-05</td> <td>   -0.230</td> <td> 0.818</td> <td>-4.78e-05</td> <td> 3.78e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(host_total_listings_count ** 2)</th>                                   <td>-6.849e-06</td> <td> 2.19e-06</td> <td>   -3.129</td> <td> 0.002</td> <td>-1.11e-05</td> <td>-2.56e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(number_of_reviews_ltm ** 2)</th>                                       <td>   -0.0007</td> <td>    0.000</td> <td>   -6.574</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_total_listings_count</th>                                           <td>    0.0094</td> <td>    0.003</td> <td>    2.916</td> <td> 0.004</td> <td>    0.003</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_reviews_ltm</th>                                               <td>   -1.1434</td> <td>    0.133</td> <td>   -8.604</td> <td> 0.000</td> <td>   -1.404</td> <td>   -0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_total_listings_count:number_of_reviews_ltm</th>                     <td>   -0.0006</td> <td>    0.000</td> <td>   -3.817</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_since_in_months</th>                                                <td>    0.0068</td> <td>    0.004</td> <td>    1.936</td> <td> 0.053</td> <td>-8.36e-05</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_since_in_months:host_total_listings_count</th>                      <td> 3.151e-05</td> <td> 2.86e-05</td> <td>    1.102</td> <td> 0.270</td> <td>-2.45e-05</td> <td> 8.76e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reviews_per_listing</th>                                                 <td>   -0.0015</td> <td>    0.003</td> <td>   -0.434</td> <td> 0.665</td> <td>   -0.008</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_since_in_months:reviews_per_listing</th>                            <td>-1.981e-05</td> <td> 2.76e-05</td> <td>   -0.718</td> <td> 0.473</td> <td>-7.39e-05</td> <td> 3.43e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reviews_per_month</th>                                                   <td>    0.1563</td> <td>    0.095</td> <td>    1.643</td> <td> 0.100</td> <td>   -0.030</td> <td>    0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_total_listings_count:reviews_per_month</th>                         <td>   -0.0058</td> <td>    0.003</td> <td>   -1.705</td> <td> 0.088</td> <td>   -0.013</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>response_rate</th>                                                       <td>   -0.4231</td> <td>    0.933</td> <td>   -0.454</td> <td> 0.650</td> <td>   -2.252</td> <td>    1.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>response_rate:number_of_reviews_ltm</th>                                 <td>    0.1083</td> <td>    0.070</td> <td>    1.558</td> <td> 0.119</td> <td>   -0.028</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceptance_rate</th>                                                     <td>    1.4505</td> <td>    0.276</td> <td>    5.258</td> <td> 0.000</td> <td>    0.910</td> <td>    1.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceptance_rate:number_of_reviews_ltm</th>                               <td>   -0.2412</td> <td>    0.048</td> <td>   -5.025</td> <td> 0.000</td> <td>   -0.335</td> <td>   -0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_scores_avg</th>                                                   <td>   -0.0639</td> <td>    0.067</td> <td>   -0.955</td> <td> 0.340</td> <td>   -0.195</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_scores_avg:number_of_reviews_ltm</th>                             <td>    0.0711</td> <td>    0.006</td> <td>   12.385</td> <td> 0.000</td> <td>    0.060</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(review_scores_cleanliness ** 3)</th>                                   <td>    0.0286</td> <td>    0.004</td> <td>    6.936</td> <td> 0.000</td> <td>    0.021</td> <td>    0.037</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                       & host\\_is\\_superhost & \\textbf{  No. Observations:  } &     4977    \\\\\n",
       "\\textbf{Model:}                                                               &        Logit        & \\textbf{  Df Residuals:      } &     4946    \\\\\n",
       "\\textbf{Method:}                                                              &         MLE         & \\textbf{  Df Model:          } &       30    \\\\\n",
       "\\textbf{Date:}                                                                &   Fri, 08 Mar 2024  & \\textbf{  Pseudo R-squ.:     } &   0.3273    \\\\\n",
       "\\textbf{Time:}                                                                &       10:53:34      & \\textbf{  Log-Likelihood:    } &   -2295.7   \\\\\n",
       "\\textbf{converged:}                                                           &         True        & \\textbf{  LL-Null:           } &   -3412.4   \\\\\n",
       "\\textbf{Covariance Type:}                                                     &      nonrobust      & \\textbf{  LLR p-value:       } &    0.000    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                              & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                            &      -4.4402  &        1.437     &    -3.090  &         0.002        &       -7.257    &       -1.623     \\\\\n",
       "\\textbf{C(response\\_time)[T.12.0]}                                            &      -0.0719  &        0.125     &    -0.576  &         0.565        &       -0.317    &        0.173     \\\\\n",
       "\\textbf{C(response\\_time)[T.24.0]}                                            &      -0.6064  &        0.200     &    -3.039  &         0.002        &       -0.997    &       -0.215     \\\\\n",
       "\\textbf{C(response\\_time)[T.72.0]}                                            &      -2.0913  &        1.082     &    -1.933  &         0.053        &       -4.212    &        0.029     \\\\\n",
       "\\textbf{C(neighbourhood\\_grouped, Treatment('West Town'))[T.Lake View]}       &       0.2990  &        0.179     &     1.674  &         0.094        &       -0.051    &        0.649     \\\\\n",
       "\\textbf{C(neighbourhood\\_grouped, Treatment('West Town'))[T.Lincoln Park]}    &       0.4459  &        0.223     &     1.998  &         0.046        &        0.009    &        0.883     \\\\\n",
       "\\textbf{C(neighbourhood\\_grouped, Treatment('West Town'))[T.Logan Square]}    &      -0.1232  &        0.197     &    -0.624  &         0.533        &       -0.510    &        0.264     \\\\\n",
       "\\textbf{C(neighbourhood\\_grouped, Treatment('West Town'))[T.Loop]}            &       0.3815  &        0.236     &     1.613  &         0.107        &       -0.082    &        0.845     \\\\\n",
       "\\textbf{C(neighbourhood\\_grouped, Treatment('West Town'))[T.Near North Side]} &      -0.2272  &        0.166     &    -1.368  &         0.171        &       -0.553    &        0.098     \\\\\n",
       "\\textbf{C(neighbourhood\\_grouped, Treatment('West Town'))[T.Near South Side]} &       0.7461  &        0.248     &     3.005  &         0.003        &        0.260    &        1.233     \\\\\n",
       "\\textbf{C(neighbourhood\\_grouped, Treatment('West Town'))[T.Near West Side]}  &      -0.1225  &        0.193     &    -0.636  &         0.525        &       -0.500    &        0.255     \\\\\n",
       "\\textbf{C(neighbourhood\\_grouped, Treatment('West Town'))[T.Other]}           &       0.0054  &        0.123     &     0.044  &         0.965        &       -0.236    &        0.247     \\\\\n",
       "\\textbf{I(host\\_since\\_in\\_months ** 2)}                                      &   -5.026e-06  &     2.18e-05     &    -0.230  &         0.818        &    -4.78e-05    &     3.78e-05     \\\\\n",
       "\\textbf{I(host\\_total\\_listings\\_count ** 2)}                                 &   -6.849e-06  &     2.19e-06     &    -3.129  &         0.002        &    -1.11e-05    &    -2.56e-06     \\\\\n",
       "\\textbf{I(number\\_of\\_reviews\\_ltm ** 2)}                                     &      -0.0007  &        0.000     &    -6.574  &         0.000        &       -0.001    &       -0.000     \\\\\n",
       "\\textbf{host\\_total\\_listings\\_count}                                         &       0.0094  &        0.003     &     2.916  &         0.004        &        0.003    &        0.016     \\\\\n",
       "\\textbf{number\\_of\\_reviews\\_ltm}                                             &      -1.1434  &        0.133     &    -8.604  &         0.000        &       -1.404    &       -0.883     \\\\\n",
       "\\textbf{host\\_total\\_listings\\_count:number\\_of\\_reviews\\_ltm}                &      -0.0006  &        0.000     &    -3.817  &         0.000        &       -0.001    &       -0.000     \\\\\n",
       "\\textbf{host\\_since\\_in\\_months}                                              &       0.0068  &        0.004     &     1.936  &         0.053        &    -8.36e-05    &        0.014     \\\\\n",
       "\\textbf{host\\_since\\_in\\_months:host\\_total\\_listings\\_count}                 &    3.151e-05  &     2.86e-05     &     1.102  &         0.270        &    -2.45e-05    &     8.76e-05     \\\\\n",
       "\\textbf{reviews\\_per\\_listing}                                                &      -0.0015  &        0.003     &    -0.434  &         0.665        &       -0.008    &        0.005     \\\\\n",
       "\\textbf{host\\_since\\_in\\_months:reviews\\_per\\_listing}                        &   -1.981e-05  &     2.76e-05     &    -0.718  &         0.473        &    -7.39e-05    &     3.43e-05     \\\\\n",
       "\\textbf{reviews\\_per\\_month}                                                  &       0.1563  &        0.095     &     1.643  &         0.100        &       -0.030    &        0.343     \\\\\n",
       "\\textbf{host\\_total\\_listings\\_count:reviews\\_per\\_month}                     &      -0.0058  &        0.003     &    -1.705  &         0.088        &       -0.013    &        0.001     \\\\\n",
       "\\textbf{response\\_rate}                                                       &      -0.4231  &        0.933     &    -0.454  &         0.650        &       -2.252    &        1.405     \\\\\n",
       "\\textbf{response\\_rate:number\\_of\\_reviews\\_ltm}                              &       0.1083  &        0.070     &     1.558  &         0.119        &       -0.028    &        0.245     \\\\\n",
       "\\textbf{acceptance\\_rate}                                                     &       1.4505  &        0.276     &     5.258  &         0.000        &        0.910    &        1.991     \\\\\n",
       "\\textbf{acceptance\\_rate:number\\_of\\_reviews\\_ltm}                            &      -0.2412  &        0.048     &    -5.025  &         0.000        &       -0.335    &       -0.147     \\\\\n",
       "\\textbf{review\\_scores\\_avg}                                                  &      -0.0639  &        0.067     &    -0.955  &         0.340        &       -0.195    &        0.067     \\\\\n",
       "\\textbf{review\\_scores\\_avg:number\\_of\\_reviews\\_ltm}                         &       0.0711  &        0.006     &    12.385  &         0.000        &        0.060    &        0.082     \\\\\n",
       "\\textbf{I(review\\_scores\\_cleanliness ** 3)}                                  &       0.0286  &        0.004     &     6.936  &         0.000        &        0.021    &        0.037     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:      host_is_superhost   No. Observations:                 4977\n",
       "Model:                          Logit   Df Residuals:                     4946\n",
       "Method:                           MLE   Df Model:                           30\n",
       "Date:                Fri, 08 Mar 2024   Pseudo R-squ.:                  0.3273\n",
       "Time:                        10:53:34   Log-Likelihood:                -2295.7\n",
       "converged:                       True   LL-Null:                       -3412.4\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "=======================================================================================================================================\n",
       "                                                                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                              -4.4402      1.437     -3.090      0.002      -7.257      -1.623\n",
       "C(response_time)[T.12.0]                                               -0.0719      0.125     -0.576      0.565      -0.317       0.173\n",
       "C(response_time)[T.24.0]                                               -0.6064      0.200     -3.039      0.002      -0.997      -0.215\n",
       "C(response_time)[T.72.0]                                               -2.0913      1.082     -1.933      0.053      -4.212       0.029\n",
       "C(neighbourhood_grouped, Treatment('West Town'))[T.Lake View]           0.2990      0.179      1.674      0.094      -0.051       0.649\n",
       "C(neighbourhood_grouped, Treatment('West Town'))[T.Lincoln Park]        0.4459      0.223      1.998      0.046       0.009       0.883\n",
       "C(neighbourhood_grouped, Treatment('West Town'))[T.Logan Square]       -0.1232      0.197     -0.624      0.533      -0.510       0.264\n",
       "C(neighbourhood_grouped, Treatment('West Town'))[T.Loop]                0.3815      0.236      1.613      0.107      -0.082       0.845\n",
       "C(neighbourhood_grouped, Treatment('West Town'))[T.Near North Side]    -0.2272      0.166     -1.368      0.171      -0.553       0.098\n",
       "C(neighbourhood_grouped, Treatment('West Town'))[T.Near South Side]     0.7461      0.248      3.005      0.003       0.260       1.233\n",
       "C(neighbourhood_grouped, Treatment('West Town'))[T.Near West Side]     -0.1225      0.193     -0.636      0.525      -0.500       0.255\n",
       "C(neighbourhood_grouped, Treatment('West Town'))[T.Other]               0.0054      0.123      0.044      0.965      -0.236       0.247\n",
       "I(host_since_in_months ** 2)                                        -5.026e-06   2.18e-05     -0.230      0.818   -4.78e-05    3.78e-05\n",
       "I(host_total_listings_count ** 2)                                   -6.849e-06   2.19e-06     -3.129      0.002   -1.11e-05   -2.56e-06\n",
       "I(number_of_reviews_ltm ** 2)                                          -0.0007      0.000     -6.574      0.000      -0.001      -0.000\n",
       "host_total_listings_count                                               0.0094      0.003      2.916      0.004       0.003       0.016\n",
       "number_of_reviews_ltm                                                  -1.1434      0.133     -8.604      0.000      -1.404      -0.883\n",
       "host_total_listings_count:number_of_reviews_ltm                        -0.0006      0.000     -3.817      0.000      -0.001      -0.000\n",
       "host_since_in_months                                                    0.0068      0.004      1.936      0.053   -8.36e-05       0.014\n",
       "host_since_in_months:host_total_listings_count                       3.151e-05   2.86e-05      1.102      0.270   -2.45e-05    8.76e-05\n",
       "reviews_per_listing                                                    -0.0015      0.003     -0.434      0.665      -0.008       0.005\n",
       "host_since_in_months:reviews_per_listing                            -1.981e-05   2.76e-05     -0.718      0.473   -7.39e-05    3.43e-05\n",
       "reviews_per_month                                                       0.1563      0.095      1.643      0.100      -0.030       0.343\n",
       "host_total_listings_count:reviews_per_month                            -0.0058      0.003     -1.705      0.088      -0.013       0.001\n",
       "response_rate                                                          -0.4231      0.933     -0.454      0.650      -2.252       1.405\n",
       "response_rate:number_of_reviews_ltm                                     0.1083      0.070      1.558      0.119      -0.028       0.245\n",
       "acceptance_rate                                                         1.4505      0.276      5.258      0.000       0.910       1.991\n",
       "acceptance_rate:number_of_reviews_ltm                                  -0.2412      0.048     -5.025      0.000      -0.335      -0.147\n",
       "review_scores_avg                                                      -0.0639      0.067     -0.955      0.340      -0.195       0.067\n",
       "review_scores_avg:number_of_reviews_ltm                                 0.0711      0.006     12.385      0.000       0.060       0.082\n",
       "I(review_scores_cleanliness ** 3)                                       0.0286      0.004      6.936      0.000       0.021       0.037\n",
       "=======================================================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula= '''host_is_superhost ~\n",
    "C(response_time) + \n",
    "\n",
    "I(host_since_in_months**2) + I(host_total_listings_count**2) +\n",
    "I(number_of_reviews_ltm**2) +\n",
    "host_total_listings_count*number_of_reviews_ltm + \n",
    "host_since_in_months*host_total_listings_count + \n",
    "host_since_in_months*reviews_per_listing + \n",
    "host_total_listings_count*reviews_per_month +\n",
    "\n",
    "response_rate*number_of_reviews_ltm + acceptance_rate*number_of_reviews_ltm +\n",
    "\n",
    "review_scores_avg*number_of_reviews_ltm + \n",
    "review_scores_avg + I(review_scores_cleanliness**3) + \n",
    "\n",
    "C(neighbourhood_grouped, Treatment('West Town'))'''\n",
    "\n",
    "# host_since_months*number_of_reviews_ltm\n",
    "\n",
    "model = smf.logit(formula=formula, data=train_final).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8a5c30c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmal\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2383: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    }
   ],
   "source": [
    "def get_acc(thresholds, model, df):\n",
    "    y_pred_prob = np.array(model.predict(df))\n",
    "    y_true = df['host_is_superhost'].values\n",
    "    \n",
    "    y_pred = y_pred_prob > thresholds[:, np.newaxis]\n",
    "    \n",
    "    y_pred_reshaped = np.repeat(y_pred[:, np.newaxis, :], len(y_true), axis=1)\n",
    "    \n",
    "    # Manually calculate accuracy so can be vectorized\n",
    "    accuracies = np.mean(y_pred_reshaped == y_true, axis=1)\n",
    "    \n",
    "    max_acc_index = np.argmax(accuracies)\n",
    "    max_acc = accuracies[max_acc_index]\n",
    "    max_acc_threshold = thresholds[max_acc_index]\n",
    "    \n",
    "    return max_acc, max_acc_threshold, max_acc_index\n",
    "\n",
    "\n",
    "\n",
    "thresholds_a = np.linspace(0.4, 0.6, num=101)\n",
    "\n",
    "max_acc_a, max_acc_threshold_a, max_acc_idx_a = get_acc(thresholds_a, model, train_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5ff16b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.4\tIndex: max_acc_idx_a\n",
      "Difference 0.002\n",
      "\n",
      "Range of Optimal Thresh [0.6, 0.402]\n"
     ]
    }
   ],
   "source": [
    "print(f'Threshold: {max_acc_threshold_a}\\tIndex: max_acc_idx_a')\n",
    "\n",
    "print('Difference', round(np.abs(thresholds_a[max_acc_idx_a]-thresholds_a[max_acc_idx_a+1]), 5))\n",
    "print(f'\\nRange of Optimal Thresh [{thresholds_a[max_acc_idx_a-1]}, {thresholds_a[max_acc_idx_a+1]}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "434fbc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmal\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2383: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    }
   ],
   "source": [
    "thresholds_b = np.linspace(thresholds_a[max_acc_idx_a-1], thresholds_a[max_acc_idx_a+1], num=101)\n",
    "\n",
    "max_acc_b, max_acc_threshold_b, max_acc_idx_b = get_acc(thresholds_b, model, train_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f6484d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.6\tIndex: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Optimal Threshold: {max_acc_threshold_b}\\tIndex: {max_acc_idx_a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "40dd8ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    3421\n",
      "True     1556\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmal\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2383: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    }
   ],
   "source": [
    "optimal_threshold = max_acc_threshold_b\n",
    "\n",
    "y_pred = model.predict(train_final) > optimal_threshold\n",
    "\n",
    "print(y_pred.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "92bd26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_score = 75.9493670886076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1bd309ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.25075346594335\n",
      "Improved by 0.9041591320072513\n",
      "(last acc_score 75.3465943339361)\n",
      "Precision: 82.19794344473009\tRecall: 58.562271062271066\n"
     ]
    }
   ],
   "source": [
    "acc_score = accuracy_score(train_final.host_is_superhost, y_pred)*100\n",
    "precision = precision_score(train_final.host_is_superhost, y_pred)*100\n",
    "recall = recall_score(train_final.host_is_superhost, y_pred)*100\n",
    "\n",
    "\n",
    "try:\n",
    "    difference = (acc_score-last_acc_score)\n",
    "        \n",
    "    if difference > 0:\n",
    "        print(acc_score)\n",
    "        print(f\"Improved by {difference}\")\n",
    "        print(f\"(last acc_score {last_acc_score})\")\n",
    "            \n",
    "    elif difference < 0:\n",
    "        print(acc_score)\n",
    "        print(f\"Decreased: {difference}\")\n",
    "        print(f\"(last acc_score {last_acc_score})\") \n",
    "\n",
    "    else: \n",
    "        print(acc_score, \"(No change)\")\n",
    "        \n",
    "except:\n",
    "    print(acc_score)\n",
    "\n",
    "\n",
    "# if acc_score >= best_score:\n",
    "#     best_score = acc_score\n",
    "#     best_formula = formula\n",
    "    \n",
    "#     print(\"\\nBest Score!\\n\")\n",
    "    \n",
    "# try:    \n",
    "#     print(f\"\\nBest Score: {best_score}\\tLast Score: {last_score}\")    \n",
    "# except:\n",
    "#     print(f\"\\nBest Score: {best_score}\")\n",
    "\n",
    "    \n",
    "print(f\"Precision: {precision}\\tRecall: {recall}\")\n",
    "    \n",
    "last_acc_score = acc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d7e98c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (model.predict(test_final) > optimal_threshold).replace({False:0, True:1})\n",
    "\n",
    "overlapping_hosts = train_final[train_final['host_id'].isin(test_final['host_id'])].drop_duplicates('host_id')[['host_id', 'host_is_superhost']]\n",
    "\n",
    "predicted_values = pd.concat([test_final[['id', 'host_id']], test_pred.rename('predicted')], axis=1)\n",
    "\n",
    "\n",
    "def overwrite(row):\n",
    "    if row['host_id'] in overlapping_hosts['host_id'].values:\n",
    "        row['predicted'] = overlapping_hosts[overlapping_hosts['host_id'] == row['host_id']]['host_is_superhost'].values[0]\n",
    "    return row\n",
    "        \n",
    "          \n",
    "predicted_values = predicted_values.apply(overwrite, axis=1)\n",
    "predicted_values = predicted_values[['id', 'predicted']].set_index('id')\n",
    "predicted_values\n",
    "\n",
    "# predicted_values.to_csv('classification_model_take_11.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
