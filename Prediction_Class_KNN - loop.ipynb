{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b1c13c80",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction Problem Report (KNN; Classification)\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b9670",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "- This is the template for the code and report on the Prediction Problem assignments.\n",
    "\n",
    "- Your code in steps 1, 3, 4, and 5 will be executed sequentially, and must produce the RMSE / accuracy claimed on Kaggle.\n",
    "\n",
    "- Your code in step 2 will also be executed, and must produce the optimal hyperparameter values used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e86f05",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1dc0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, cross_validate, GridSearchCV, RandomizedSearchCV, KFold, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, mean_squared_error\n",
    "from scipy.stats import uniform\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06025554",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('../Datasets/train_classification.csv') # use reg data for class?\n",
    "raw_test = pd.read_csv('../Datasets/test_classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d4b16",
   "metadata": {},
   "source": [
    "## 1) Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc06dc",
   "metadata": {},
   "source": [
    "Put the data pre-processing code. You don't need to explain it. You may use the same code from last quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2dc424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of the raw datasets\n",
    "train = raw_train.copy()\n",
    "test = raw_test.copy()\n",
    "\n",
    "# Convert 'host_acceptance_rate' and 'host_response_rate' columns to float and scale by dividing by 100\n",
    "train['acceptance_rate'] = train['host_acceptance_rate'].str.replace('%', '').astype(float) / 100\n",
    "train['response_rate'] = train['host_response_rate'].str.replace('%', '').astype(float) / 100\n",
    "\n",
    "test['acceptance_rate'] = test['host_acceptance_rate'].str.replace('%', '').astype(float) / 100\n",
    "test['response_rate'] = test['host_response_rate'].str.replace('%', '').astype(float) / 100\n",
    "\n",
    "# Drop unnecessary columns\n",
    "train.drop(columns=['host_acceptance_rate', 'host_response_rate'], inplace=True)\n",
    "test.drop(columns=['host_acceptance_rate', 'host_response_rate'], inplace=True)\n",
    "\n",
    "\n",
    "# Extract numeric values from 'bathrooms_text' column and convert to float\n",
    "train['bathrooms_num'] = train['bathrooms_text'].str.extract('(\\d+)').astype(float)\n",
    "test['bathrooms_num'] = test['bathrooms_text'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "# Fill missing values in 'bathrooms_num' where 'Half-bath' is mentioned in 'bathrooms_text' with 0.5\n",
    "train.loc[train['bathrooms_text'].str.contains('Half-bath', case=False, na=False) & train['bathrooms_num'].isna(), 'bathrooms_num'] = 0.5\n",
    "test.loc[test['bathrooms_text'].str.contains('Half-bath', case=False, na=False) & test['bathrooms_num'].isna(), 'bathrooms_num'] = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aabab82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "def strip_date(row):\n",
    "    if isinstance(row, str):\n",
    "        row = datetime.strptime(row, '%Y-%m-%d').date()\n",
    "    return row\n",
    "\n",
    "# Apply date conversion to train dataset\n",
    "train['host_since'] = train['host_since'].apply(strip_date)\n",
    "train['first_review'] = train['first_review'].apply(strip_date)\n",
    "train['last_review'] = train['last_review'].apply(strip_date)\n",
    "\n",
    "# Apply date conversion to test dataset\n",
    "test['host_since'] = test['host_since'].apply(strip_date)\n",
    "test['first_review'] = test['first_review'].apply(strip_date)\n",
    "test['last_review'] = test['last_review'].apply(strip_date)\n",
    "\n",
    "# ----- #\n",
    "\n",
    "# Calculate months since various dates for train dataset\n",
    "train['host_since_in_months'] = round(((datetime.now().date() - train['host_since']).dt.days) / 30, 2)\n",
    "train['first_review_in_months'] = round(((datetime.now().date() - train['first_review']).dt.days) / 30, 2)\n",
    "train['last_review_in_months'] = round(((datetime.now().date() - train['last_review']).dt.days) / 30, 2)\n",
    "\n",
    "# Calculate months since various dates for test dataset\n",
    "test['host_since_in_months'] = round(((datetime.now().date() - test['host_since']).dt.days) / 30,  2)\n",
    "test['first_review_in_months'] = round(((datetime.now().date() - test['first_review']).dt.days) / 30, 2)\n",
    "test['last_review_in_months'] = round(((datetime.now().date() - test['last_review']).dt.days) / 30, 2)\n",
    "\n",
    "\n",
    "train_clean = train.drop(columns=['host_since', 'first_review', 'last_review'])\n",
    "test_clean = test.drop(columns=['host_since', 'first_review', 'last_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50074133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for response time category conversions\n",
    "response_time_dict = {'within an hour': 1, 'within a few hours': 12, 'within a day': 24, 'a few days or more': 72}\n",
    "\n",
    "def replace_response_time(row):\n",
    "    if pd.notna(row):\n",
    "        return response_time_dict.get(row)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "train_clean['response_time'] = train_clean['host_response_time'].apply(replace_response_time)\n",
    "test_clean['response_time'] = test_clean['host_response_time'].apply(replace_response_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb25d2",
   "metadata": {},
   "source": [
    "Clean Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3583ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_vars(row):\n",
    "    # Check if 'shared' is in 'bathrooms_text' to identify shared bathrooms\n",
    "    if 'shared' in str(row['bathrooms_text']):\n",
    "        row['bathrooms_shared'] = \"t\"\n",
    "        \n",
    "    # Check if 'bathrooms_text' is empty and 'room_type' is 'Shared' to identify shared bathrooms\n",
    "    elif pd.isna(row['bathrooms_text']):\n",
    "        if 'Shared' in row['room_type']:\n",
    "            row['bathrooms_shared'] = \"t\"              \n",
    "        else:\n",
    "            row['bathrooms_shared'] = \"f\"\n",
    "    else: \n",
    "        row['bathrooms_shared'] = \"f\"\n",
    "        \n",
    "    # Convert 'Hotel room' room type to 'Private room'\n",
    "    if row.loc['room_type'] == 'Hotel room':\n",
    "        row['room_type'] = 'Private room'\n",
    "        \n",
    "    return row\n",
    "\n",
    "# Apply the function to clean variables to train and test datasets\n",
    "train_clean = train_clean.apply(clean_vars, axis=1)\n",
    "test_clean = test_clean.apply(clean_vars, axis=1)\n",
    "\n",
    "\n",
    "# create variables for rate of reviews for listing count and for host_since_months\n",
    "train_clean['reviews_per_listing'] = train_clean['number_of_reviews']/train_clean['calculated_host_listings_count']\n",
    "train_clean['reviews_per_month'] = train_clean['number_of_reviews']/train_clean['host_since_in_months']\n",
    "train_clean['reviews_per_listing_per_month'] = train_clean['reviews_per_listing']/train_clean['host_since_in_months']\n",
    "\n",
    "test_clean['reviews_per_listing'] = test_clean['number_of_reviews']/test_clean['calculated_host_listings_count']\n",
    "test_clean['reviews_per_month'] = test_clean['number_of_reviews']/test_clean['host_since_in_months']\n",
    "test_clean['reviews_per_listing_per_month'] = test_clean['reviews_per_listing']/test_clean['host_since_in_months']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df51a6",
   "metadata": {},
   "source": [
    "clean neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75065138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if neighbourhood has less than 150 occurances group them into 'Other'\n",
    "neighbourhood_counts = train_clean['neighbourhood_cleansed'].value_counts()  \n",
    "test_only_hoods = [i for i in test_clean['neighbourhood_cleansed'].unique() \n",
    "                   if i not in neighbourhood_counts \n",
    "                   and i != 'Other']\n",
    "\n",
    "\n",
    "other_hoods = []\n",
    "for i in neighbourhood_counts.index:\n",
    "    if neighbourhood_counts[i] < 150:\n",
    "        other_hoods.append(i)         \n",
    "    \n",
    "def clean_hoods(row):\n",
    "    if row.loc['neighbourhood_cleansed'] in other_hoods or row.loc['neighbourhood_cleansed'] in test_only_hoods:\n",
    "        row['neighbourhood_grouped'] = 'Other'\n",
    "        \n",
    "    else:    \n",
    "        row['neighbourhood_grouped'] = row.loc['neighbourhood_cleansed']\n",
    "        \n",
    "    return row\n",
    "   \n",
    "    \n",
    "train_clean = train_clean.apply(clean_hoods, axis=1)  \n",
    "test_clean = test_clean.apply(clean_hoods, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0fa3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean filler words out of property types\n",
    "words_to_remove = ['place', 'room', 'private', 'shared', 'entire', ' in', ' room', ' private', ' shared', ' entire', ' in',]\n",
    "\n",
    "def remove_words(text):\n",
    "    text=text.lower()\n",
    "    for word in words_to_remove:\n",
    "        word = word.lower()\n",
    "        text = text.replace(word, '')\n",
    "    return text.strip()\n",
    "\n",
    "train_clean['property_type'] = train_clean['property_type'].apply(remove_words)\n",
    "test_clean['property_type'] = test_clean['property_type'].apply(remove_words)\n",
    "\n",
    "\n",
    "# group properties with less than 10 occurances into 'Other'\n",
    "property_counts = train_clean['property_type'].value_counts()\n",
    "keep = [i for i in property_counts.index if property_counts[i] > 10]\n",
    "\n",
    "def clean_property(row):\n",
    "    if row not in keep or row == \"\":\n",
    "        row = 'Other'\n",
    "      \n",
    "    return row\n",
    "\n",
    "train_clean['property_type_cleansed'] = train_clean['property_type'].apply(clean_property)\n",
    "test_clean['property_type_cleansed'] = test_clean['property_type'].apply(clean_property)\n",
    "\n",
    "train_filter_1 = train_clean.copy()\n",
    "test_filter_1 = test_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff0f6ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "host_hood_counts = train_filter_1['host_neighbourhood'].value_counts()\n",
    "keep_host_hood = host_hood_counts[host_hood_counts >= 5].index\n",
    "\n",
    "train_filter_1['host_neighbourhood'] = train_filter_1['host_neighbourhood'].apply(lambda x: 'Other' if x not in keep_host_hood else x)\n",
    "test_filter_1['host_neighbourhood'] = test_filter_1['host_neighbourhood'].apply(lambda x: 'Other' if x not in keep_host_hood else x)\n",
    "# train_final[['host_neighbourhood']].value_counts()\n",
    "# test_final[['host_neighbourhood']].value_counts()\n",
    "\n",
    "# ----- #\n",
    "\n",
    "host_loc_counts = train_filter_1['host_location'].value_counts()\n",
    "keep_host_loc = host_loc_counts[host_loc_counts >= 10].index\n",
    "\n",
    "train_filter_1['host_location'] = train_filter_1['host_location'].apply(lambda x: 'Other' if x not in keep_host_loc else x)\n",
    "test_filter_1['host_location'] = test_filter_1['host_location'].apply(lambda x: 'Other' if x not in keep_host_loc else x)\n",
    "# train_final['host_location'].value_counts()\n",
    "# test_final['host_location'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a378ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_filter_1['host_verifications'] = train_filter_1['host_verifications'].apply(ast.literal_eval)\n",
    "except: pass\n",
    "\n",
    "try:\n",
    "    test_filter_1['host_verifications'] = test_filter_1['host_verifications'].apply(ast.literal_eval)\n",
    "except: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f76a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter_1['num_verifications'] = train_filter_1['host_verifications'].apply(len)\n",
    "test_filter_1['num_verifications'] = test_filter_1['host_verifications'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4b8492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vers(df):\n",
    "    def update_verification(row):\n",
    "        ver_phone = 't' if 'phone' in row['host_verifications'] else 'f'\n",
    "        ver_email = 't' if 'email' in row['host_verifications'] else 'f'\n",
    "        ver_work_email = 't' if 'work_email' in row['host_verifications'] else 'f'\n",
    "        return pd.Series({'ver_phone': ver_phone, 'ver_email': ver_email, 'ver_work_email': ver_work_email})\n",
    "\n",
    "    df[['ver_phone', 'ver_email', 'ver_work_email']] = df.apply(update_verification, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_filter_2 = split_vers(train_filter_1).drop('host_verifications', axis=1)\n",
    "test_filter_2 = split_vers(test_filter_1).drop('host_verifications', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5eb2f",
   "metadata": {},
   "source": [
    "Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c90ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in remaining missing values with median for numerical columns\n",
    "train_filter_2.fillna(train_filter_2.median(numeric_only=True), inplace=True)\n",
    "test_filter_2.fillna(test_filter_2.median(numeric_only=True), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d941c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review scores are very correlated, average review scores to handle this\n",
    "train_filter_2['review_scores_avg'] = np.mean(train_filter_2[['review_scores_accuracy', 'review_scores_checkin', 'review_scores_communication', 'review_scores_rating', 'review_scores_value', 'review_scores_location', 'review_scores_cleanliness']], axis=1)\n",
    "test_filter_2['review_scores_avg'] = np.mean(test_filter_2[['review_scores_accuracy', 'review_scores_checkin', 'review_scores_communication', 'review_scores_rating', 'review_scores_value', 'review_scores_location', 'review_scores_cleanliness']], axis=1)\n",
    "\n",
    "train_filter_2.drop(columns=['review_scores_accuracy', 'review_scores_checkin', 'review_scores_communication', 'review_scores_rating', 'review_scores_value', 'review_scores_location', 'review_scores_cleanliness'], inplace=True)\n",
    "test_filter_2.drop(columns=['review_scores_accuracy', 'review_scores_checkin', 'review_scores_communication', 'review_scores_rating', 'review_scores_value', 'review_scores_location', 'review_scores_cleanliness'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8aa688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter_2['host_is_superhost'] = train_filter_2['host_is_superhost'].replace({\"f\":False, \"t\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45ce5f85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>maximum_nights_avg_ntm</td>\n",
       "      <td>4.144099e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>minimum_maximum_nights</td>\n",
       "      <td>2.203381e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>maximum_maximum_nights</td>\n",
       "      <td>4.310222e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>calculated_host_listings_count</td>\n",
       "      <td>3.713006e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>calculated_host_listings_count_entire_homes</td>\n",
       "      <td>3.691391e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>availability_60</td>\n",
       "      <td>2.558071e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>minimum_nights_avg_ntm</td>\n",
       "      <td>1.924540e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>response_rate</td>\n",
       "      <td>1.636986e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>review_scores_avg</td>\n",
       "      <td>1.587833e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>availability_90</td>\n",
       "      <td>1.566422e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>host_listings_count</td>\n",
       "      <td>1.292554e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>calculated_host_listings_count_private_rooms</td>\n",
       "      <td>1.069955e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>host_total_listings_count</td>\n",
       "      <td>5.012599e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minimum_nights</td>\n",
       "      <td>4.305512e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>availability_30</td>\n",
       "      <td>4.101652e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>acceptance_rate</td>\n",
       "      <td>3.433901e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>num_verifications</td>\n",
       "      <td>1.713913e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>minimum_minimum_nights</td>\n",
       "      <td>1.642863e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>reviews_per_month</td>\n",
       "      <td>1.238583e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>reviews_per_listing</td>\n",
       "      <td>1.180395e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accommodates</td>\n",
       "      <td>1.176193e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beds</td>\n",
       "      <td>1.156609e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>number_of_reviews</td>\n",
       "      <td>1.151528e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>reviews_per_listing_per_month</td>\n",
       "      <td>1.076159e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>maximum_minimum_nights</td>\n",
       "      <td>1.067506e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>host_since_in_months</td>\n",
       "      <td>9.605269e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>availability_365</td>\n",
       "      <td>7.868305e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bathrooms_num</td>\n",
       "      <td>7.599104e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>number_of_reviews_ltm</td>\n",
       "      <td>6.528811e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>first_review_in_months</td>\n",
       "      <td>6.285304e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Predictor           VIF\n",
       "11                        maximum_nights_avg_ntm  4.144099e+11\n",
       "8                         minimum_maximum_nights  2.203381e+11\n",
       "9                         maximum_maximum_nights  4.310222e+10\n",
       "19                calculated_host_listings_count  3.713006e+04\n",
       "20   calculated_host_listings_count_entire_homes  3.691391e+04\n",
       "13                               availability_60  2.558071e+02\n",
       "10                        minimum_nights_avg_ntm  1.924540e+02\n",
       "25                                 response_rate  1.636986e+02\n",
       "34                             review_scores_avg  1.587833e+02\n",
       "14                               availability_90  1.566422e+02\n",
       "0                            host_listings_count  1.292554e+02\n",
       "21  calculated_host_listings_count_private_rooms  1.069955e+02\n",
       "1                      host_total_listings_count  5.012599e+01\n",
       "4                                 minimum_nights  4.305512e+01\n",
       "12                               availability_30  4.101652e+01\n",
       "24                               acceptance_rate  3.433901e+01\n",
       "33                             num_verifications  1.713913e+01\n",
       "6                         minimum_minimum_nights  1.642863e+01\n",
       "23                             reviews_per_month  1.238583e+01\n",
       "31                           reviews_per_listing  1.180395e+01\n",
       "2                                   accommodates  1.176193e+01\n",
       "3                                           beds  1.156609e+01\n",
       "16                             number_of_reviews  1.151528e+01\n",
       "32                 reviews_per_listing_per_month  1.076159e+01\n",
       "7                         maximum_minimum_nights  1.067506e+01\n",
       "27                          host_since_in_months  9.605269e+00\n",
       "15                              availability_365  7.868305e+00\n",
       "26                                 bathrooms_num  7.599104e+00\n",
       "17                         number_of_reviews_ltm  6.528811e+00\n",
       "28                        first_review_in_months  6.285304e+00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "non_numeric_columns = train_filter_2.select_dtypes(exclude=[np.number]).columns\n",
    "data_numeric = train_filter_2.drop(columns=non_numeric_columns)\n",
    "\n",
    "X = data_numeric.drop(columns=['host_id', 'id', 'latitude', 'longitude'])\n",
    "y = train_filter_2.host_is_superhost\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Predictor\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "vif[vif['VIF'] >= 5].sort_values('VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "299e21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter_3 = train_filter_2.drop(columns=['availability_60', 'availability_90', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'minimum_minimum_nights', 'minimum_maximum_nights', 'maximum_minimum_nights', 'maximum_maximum_nights'])\n",
    "test_filter_3 = test_filter_2.drop(columns=['availability_60', 'availability_90', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'minimum_minimum_nights', 'minimum_maximum_nights', 'maximum_minimum_nights', 'maximum_maximum_nights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50df9d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>response_rate</td>\n",
       "      <td>162.468319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>review_scores_avg</td>\n",
       "      <td>158.295920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>host_listings_count</td>\n",
       "      <td>114.321915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>host_total_listings_count</td>\n",
       "      <td>48.292613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>minimum_nights_avg_ntm</td>\n",
       "      <td>45.241613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>acceptance_rate</td>\n",
       "      <td>34.067081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>num_verifications</td>\n",
       "      <td>16.427689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>reviews_per_month</td>\n",
       "      <td>12.251551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accommodates</td>\n",
       "      <td>11.671614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>reviews_per_listing</td>\n",
       "      <td>11.617984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beds</td>\n",
       "      <td>11.466622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>number_of_reviews</td>\n",
       "      <td>11.213979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>reviews_per_listing_per_month</td>\n",
       "      <td>10.566220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minimum_nights</td>\n",
       "      <td>9.982476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>host_since_in_months</td>\n",
       "      <td>9.567836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bathrooms_num</td>\n",
       "      <td>7.544826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>number_of_reviews_ltm</td>\n",
       "      <td>6.485286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>first_review_in_months</td>\n",
       "      <td>6.267626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>availability_365</td>\n",
       "      <td>5.665648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Predictor         VIF\n",
       "17                  response_rate  162.468319\n",
       "26              review_scores_avg  158.295920\n",
       "0             host_listings_count  114.321915\n",
       "1       host_total_listings_count   48.292613\n",
       "6          minimum_nights_avg_ntm   45.241613\n",
       "16                acceptance_rate   34.067081\n",
       "25              num_verifications   16.427689\n",
       "15              reviews_per_month   12.251551\n",
       "2                    accommodates   11.671614\n",
       "23            reviews_per_listing   11.617984\n",
       "3                            beds   11.466622\n",
       "10              number_of_reviews   11.213979\n",
       "24  reviews_per_listing_per_month   10.566220\n",
       "4                  minimum_nights    9.982476\n",
       "19           host_since_in_months    9.567836\n",
       "18                  bathrooms_num    7.544826\n",
       "11          number_of_reviews_ltm    6.485286\n",
       "20         first_review_in_months    6.267626\n",
       "9                availability_365    5.665648"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numeric_columns = train_filter_3.select_dtypes(exclude=[np.number]).columns\n",
    "data_numeric = train_filter_3.drop(columns=non_numeric_columns)\n",
    "\n",
    "X = data_numeric.drop(columns=['host_id', 'id', 'latitude', 'longitude'])\n",
    "y = train_filter_3.host_is_superhost\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Predictor\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "vif[vif['VIF'] >= 5].sort_values('VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54423f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter_4 = train_filter_3.drop(columns=['host_listings_count', 'response_rate'])\n",
    "test_filter_4 = test_filter_3.drop(columns=['host_listings_count', 'response_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f52025d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>review_scores_avg</td>\n",
       "      <td>50.532960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>acceptance_rate</td>\n",
       "      <td>30.401089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>num_verifications</td>\n",
       "      <td>16.233927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>minimum_nights_avg_ntm</td>\n",
       "      <td>15.105715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reviews_per_month</td>\n",
       "      <td>12.220500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accommodates</td>\n",
       "      <td>11.618679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>reviews_per_listing</td>\n",
       "      <td>11.615309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beds</td>\n",
       "      <td>11.463107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>number_of_reviews</td>\n",
       "      <td>11.192710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>reviews_per_listing_per_month</td>\n",
       "      <td>10.563730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>host_total_listings_count</td>\n",
       "      <td>9.587251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>host_since_in_months</td>\n",
       "      <td>9.500790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bathrooms_num</td>\n",
       "      <td>7.520711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>number_of_reviews_ltm</td>\n",
       "      <td>6.482044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>first_review_in_months</td>\n",
       "      <td>6.266991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>availability_365</td>\n",
       "      <td>5.636224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Predictor        VIF\n",
       "24              review_scores_avg  50.532960\n",
       "15                acceptance_rate  30.401089\n",
       "23              num_verifications  16.233927\n",
       "5          minimum_nights_avg_ntm  15.105715\n",
       "14              reviews_per_month  12.220500\n",
       "1                    accommodates  11.618679\n",
       "21            reviews_per_listing  11.615309\n",
       "2                            beds  11.463107\n",
       "9               number_of_reviews  11.192710\n",
       "22  reviews_per_listing_per_month  10.563730\n",
       "0       host_total_listings_count   9.587251\n",
       "17           host_since_in_months   9.500790\n",
       "16                  bathrooms_num   7.520711\n",
       "10          number_of_reviews_ltm   6.482044\n",
       "18         first_review_in_months   6.266991\n",
       "8                availability_365   5.636224"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numeric_columns = train_filter_4.select_dtypes(exclude=[np.number]).columns\n",
    "data_numeric = train_filter_4.drop(columns=non_numeric_columns)\n",
    "\n",
    "X = data_numeric.drop(columns=['host_id', 'id', 'latitude', 'longitude'])\n",
    "y = train_filter_4.host_is_superhost\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Predictor\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "vif[vif['VIF'] >= 5].sort_values('VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b80f4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final DataFrames\n",
    "train_final = train_filter_4.copy()\n",
    "test_final = test_filter_4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eaefd",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b39b7",
   "metadata": {},
   "source": [
    "### How many attempts did it take you to tune the model hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e33d51",
   "metadata": {},
   "source": [
    "I attempted the model hyperparameters and tuning about 11 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f50fd",
   "metadata": {},
   "source": [
    "### Which tuning method did you use (grid search / Bayes search / etc.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea3666",
   "metadata": {},
   "source": [
    "I used loops and added each combinations values to a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0da667",
   "metadata": {},
   "source": [
    "### What challenges did you face while tuning the hyperparameters, and what actions did you take to address those challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8149e",
   "metadata": {},
   "source": [
    "Originally I used GridSearchCV, but changed to loops so I could tune the threshold along with n_neighbors and weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26daac",
   "metadata": {},
   "source": [
    "### How many hours did you spend on hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8149d3",
   "metadata": {},
   "source": [
    "I spent approximately 5 hours tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4abb9",
   "metadata": {},
   "source": [
    "**Paste the hyperparameter tuning code below. You must show at least one hyperparameter tuning procedure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6462944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, cross_validate, GridSearchCV, GridSearchCV, RandomizedSearchCV, KFold, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55b519a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmal\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:227: UserWarning: Found unknown categories in columns [5, 6, 8] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = train_final.select_dtypes(include=['number']).drop(columns=['id']).columns\n",
    "\n",
    "X_train = train_final.drop(columns=['host_is_superhost', 'id'])\n",
    "X_test = test_final.drop(columns=['id'])\n",
    "train_final\n",
    "X_train_num = X_train[numeric_columns]\n",
    "y_train = train_final.host_is_superhost\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train_num)\n",
    "\n",
    "X_train_scaled = sc.transform(X_train[numeric_columns])\n",
    "X_test_scaled = sc.transform(X_test[numeric_columns])\n",
    "\n",
    "X_train_num_scaled = pd.DataFrame(X_train_scaled, columns=numeric_columns)\n",
    "X_test_num_scaled = pd.DataFrame(X_test_scaled, columns=numeric_columns)\n",
    "\n",
    "\n",
    "train_testing = train_final.drop(columns=['host_is_superhost']) # 'host_location', 'host_neighbourhood', \n",
    "test_testing = test_final  #.drop(columns=['host_location', 'host_neighbourhood'])\n",
    "\n",
    "train_testing_cat = train_testing.select_dtypes(exclude=['number'])\n",
    "test_testing_cat = test_testing.select_dtypes(exclude=['number'])\n",
    "\n",
    "\n",
    "\n",
    "enc = OneHotEncoder(drop='if_binary', handle_unknown='ignore')\n",
    "enc.fit(train_testing_cat)\n",
    "\n",
    "drop_enc = enc.transform(train_testing_cat)\n",
    "drop_enc_test = enc.transform(test_testing_cat)\n",
    "\n",
    "train_encoded_df = pd.DataFrame(drop_enc.toarray(), columns=enc.get_feature_names_out(train_testing_cat.columns))\n",
    "test_encoded_df = pd.DataFrame(drop_enc_test.toarray(), columns=enc.get_feature_names_out(test_testing_cat.columns))\n",
    "\n",
    "X_train_final = pd.concat([X_train_num_scaled, train_encoded_df], axis=1)\n",
    "X_test_final = pd.concat([X_test_num_scaled, test_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b69cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_power_2(distance):\n",
    "    return 1/(1e-10+distance**2)\n",
    "def dist_power_3(distance):\n",
    "    return 1/(1e-10+distance**3)\n",
    "def dist_power_4(distance):\n",
    "    return 1/(1e-10+distance**4)\n",
    "def dist_power_5(distance):\n",
    "    return 1/(1e-10+distance**5)\n",
    "\n",
    "def dist_power_6(distance):\n",
    "    return 1/(1e-10+distance**6)\n",
    "def dist_power_7(distance):\n",
    "    return 1/(1e-10+distance**7)\n",
    "def dist_power_8(distance):\n",
    "    return 1/(1e-10+distance**8)\n",
    "def dist_power_9(distance):\n",
    "    return 1/(1e-10+distance**9)\n",
    "def dist_power_10(distance):\n",
    "    return 1/(1e-10+distance**10)\n",
    "\n",
    "def dist_power_11(distance):\n",
    "    return 1/(1e-10+distance**11)\n",
    "def dist_power_12(distance):\n",
    "    return 1/(1e-10+distance**12)\n",
    "def dist_power_13(distance):\n",
    "    return 1/(1e-10+distance**13)\n",
    "def dist_power_14(distance):\n",
    "    return 1/(1e-10+distance**14)\n",
    "def dist_power_15(distance):\n",
    "    return 1/(1e-10+distance**15)\n",
    "\n",
    "def dist_power_16(distance):\n",
    "    return 1/(1e-10+distance**16)\n",
    "def dist_power_17(distance):\n",
    "    return 1/(1e-10+distance**17)\n",
    "def dist_power_18(distance):\n",
    "    return 1/(1e-10+distance**18)\n",
    "def dist_power_19(distance):\n",
    "    return 1/(1e-10+distance**19)\n",
    "def dist_power_20(distance):\n",
    "    return 1/(1e-10+distance**20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46620546",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6e76dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_k_step = 25\n",
    "first_thr_step = 0.1\n",
    "\n",
    "cv_settings = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab910f06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "400\n",
      "425\n",
      "450\n",
      "475\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.3, 0.8, first_thr_step)\n",
    "Ks = np.arange(50, 525, first_k_step)\n",
    "weight_options = [dist_power_6, dist_power_7, dist_power_8, dist_power_9, dist_power_10, dist_power_11, dist_power_12]\n",
    "\n",
    "param_df = pd.DataFrame(columns = ['K', 'weight', 'thr', 'acc'])\n",
    "counter = 0\n",
    "\n",
    "# Loop through each parameter combination\n",
    "for K in Ks:\n",
    "    print(K)\n",
    "    \n",
    "    for weight in weight_options:\n",
    "        model = KNeighborsClassifier(n_neighbors=K, weights=weight)\n",
    "        y_pred_probas = cross_val_predict(model, X_train_final, y_train, cv=cv_settings, method='predict_proba')[:, 1]\n",
    "        \n",
    "        for thr in thresholds:\n",
    "            param_df.loc[counter, 'acc'] = accuracy_score(y_train, (y_pred_probas > thr))\n",
    "            param_df.loc[counter, 'K'] = K\n",
    "            param_df.loc[counter, 'thr'] = thr\n",
    "            param_df.loc[counter, 'weight'] = weight\n",
    "        \n",
    "            counter += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "689ae672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, <function dist_power_9 at 0x00000193519467A0>, 0.6)\n"
     ]
    }
   ],
   "source": [
    "best_entry = param_df[param_df['acc'] == param_df['acc'].max()]\n",
    "\n",
    "best_k, best_weight, best_thr = np.array(best_entry[['K', 'weight', 'thr']])[0].tolist()\n",
    "best_thr = round(best_thr, 3)\n",
    "\n",
    "print((best_k, best_weight, best_thr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e13fd",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb5cb371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 30 5 0.6 0.12 0.05\n",
      "95\n",
      "100\n",
      "105\n",
      "110\n",
      "115\n",
      "120\n",
      "125\n",
      "130\n",
      "135\n",
      "140\n",
      "145\n",
      "150\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "next_k_range = int(np.ceil(first_k_step + first_k_step/5))\n",
    "next_k_step = 5\n",
    "next_thr_range = round(first_thr_step + first_thr_step/5, 3)\n",
    "next_thr_step = 0.05\n",
    "\n",
    "new_Ks = np.arange(best_k-next_k_range, best_k+next_k_step+next_k_range, next_k_step)\n",
    "new_thresholds = np.arange(best_thr-next_thr_range, best_thr+next_thr_range+next_thr_step, next_thr_step)\n",
    "new_weights = [dist_power_6, dist_power_7, dist_power_8, dist_power_9, dist_power_10]\n",
    "\n",
    "print(best_k, next_k_range, next_k_step, best_thr, next_thr_range, next_thr_step)\n",
    "\n",
    "param_df_2 = pd.DataFrame(columns = ['K', 'weight', 'thr', 'acc'])\n",
    "counter = 0\n",
    "\n",
    "# Loop through each parameter combination\n",
    "for K in new_Ks:\n",
    "    print(K)\n",
    "    for weight in new_weights:\n",
    "        model = KNeighborsClassifier(n_neighbors=K, weights=weight)\n",
    "        y_pred_probas = cross_val_predict(model, X_train_final, y_train, cv=cv_settings, method='predict_proba')[:, 1]\n",
    "        \n",
    "        for thr in new_thresholds:\n",
    "            param_df_2.loc[counter, 'K'] = K\n",
    "            param_df_2.loc[counter, 'thr'] = thr\n",
    "            param_df_2.loc[counter, 'weight'] = weight\n",
    "            param_df_2.loc[counter, 'acc'] = accuracy_score(y_train, (y_pred_probas > thr))\n",
    "        \n",
    "            counter += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e07e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, <function dist_power_8 at 0x0000019351946700>, 0.58)\n"
     ]
    }
   ],
   "source": [
    "best_entry_2 = param_df_2[param_df_2['acc'] == param_df_2['acc'].max()]\n",
    "    \n",
    "best_k_2, best_weight_2, best_thr_2 = np.array(best_entry_2[['K', 'weight', 'thr']])[0].tolist()\n",
    "best_thr_2 = round(best_thr_2, 4)\n",
    "\n",
    "print((best_k_2, best_weight_2, best_thr_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d8a5957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 6 1 0.58 0.06 0.01\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "next_k_range_2 = int(np.ceil(next_k_step + next_k_step/5))\n",
    "next_k_step_2 = 1\n",
    "next_thr_range_2 = round(next_thr_step + next_thr_step/5, 3)\n",
    "next_thr_step_2 = 0.01\n",
    "\n",
    "new_Ks_2 = np.arange(best_k_2-next_k_range_2, best_k_2+next_k_step_2+next_k_range_2, next_k_step_2)\n",
    "new_thresholds_2 = np.arange(best_thr_2-next_thr_range_2, best_thr_2+next_thr_range_2+next_thr_step_2, next_thr_step_2)\n",
    "new_weights_2 = [dist_power_5, dist_power_6, dist_power_7, dist_power_8, dist_power_9]\n",
    "\n",
    "print(best_k_2, next_k_range_2, next_k_step_2, best_thr_2, next_thr_range_2, next_thr_step_2)\n",
    "\n",
    "param_df_3 = pd.DataFrame(columns = ['K', 'weight', 'thr', 'acc'])\n",
    "counter = 0\n",
    "\n",
    "# Loop through each parameter combination\n",
    "for K in new_Ks_2:\n",
    "    print(K)\n",
    "    for weight in new_weights_2:\n",
    "        model = KNeighborsClassifier(n_neighbors=K, weights=weight)\n",
    "        y_pred_probas = cross_val_predict(model, X_train_final, y_train, cv=cv_settings, method='predict_proba')[:, 1]\n",
    "        \n",
    "        for thr in new_thresholds_2:\n",
    "            param_df_3.loc[counter, 'K'] = K\n",
    "            param_df_3.loc[counter, 'thr'] = thr\n",
    "            param_df_3.loc[counter, 'weight'] = weight\n",
    "            param_df_3.loc[counter, 'acc'] = accuracy_score(y_train, (y_pred_probas > thr))\n",
    "        \n",
    "            counter += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb73b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_entry_3 = param_df_3[param_df_3['acc'] == param_df_3['acc'].max()]\n",
    "    \n",
    "best_k_3, best_weight_3, best_thr_3 = np.array(best_entry_3[['K', 'weight', 'thr']])[0].tolist()\n",
    "best_thr_3 = round(best_thr_3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc357d",
   "metadata": {},
   "source": [
    "**Paste the optimal hyperparameter values below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((best_k_3, best_weight_3, best_thr_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d697af6",
   "metadata": {},
   "source": [
    "n_neighbors=25, weights=dist_power_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e104de7",
   "metadata": {},
   "source": [
    "## 3) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92eb0d9",
   "metadata": {},
   "source": [
    "### Create Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d533eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=best_k_3, weights=best_weight_3).fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf8491",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31202106",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_test = pd.DataFrame((model.predict_proba(X_test_final)[:, 1] > best_thr_3)).rename({0:'predicted'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12394c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1543972437713169913</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710552057351883447</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97075525</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83734823</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56722823</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44798957</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929899281829298917</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36015595</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472538040789213113</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79743915</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3324 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     predicted\n",
       "id                            \n",
       "1543972437713169913      False\n",
       "1710552057351883447      False\n",
       "97075525                  True\n",
       "83734823                  True\n",
       "56722823                 False\n",
       "...                        ...\n",
       "44798957                  True\n",
       "1929899281829298917       True\n",
       "36015595                 False\n",
       "1472538040789213113      False\n",
       "79743915                  True\n",
       "\n",
       "[3324 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values = pd.concat([test_final[['id', 'host_id']], y_preds_test], axis=1)\n",
    "overlapping_hosts = train_final[train_final['host_id'].isin(test_final['host_id'])].drop_duplicates('host_id')[['host_id', 'host_is_superhost']]\n",
    "\n",
    "def overwrite(row):\n",
    "    if row['host_id'] in overlapping_hosts['host_id'].values:\n",
    "        row['predicted'] = overlapping_hosts[overlapping_hosts['host_id'] == row['host_id']]['host_is_superhost'].values[0]\n",
    "    return row\n",
    "        \n",
    "predicted_values = predicted_values.apply(overwrite, axis=1)\n",
    "predicted_values = predicted_values[['id', 'predicted']].set_index('id')\n",
    "predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d6954",
   "metadata": {},
   "source": [
    "## 4) Put any ad-hoc steps for further improving model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c5d42",
   "metadata": {},
   "source": [
    "## 5) Export the predictions in the format required to submit on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f462c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values.to_csv('pred_csvs/KNN_class_model.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
